{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia de proi_file_generator",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqg--kSJBi1r"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "NXCgG5y6BzuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "\n",
        "#first put a shortcut in your drive to the image processing folder\n",
        "\n",
        "\n",
        "DATA_DIR = os.path.join('/content',\n",
        "                        'drive',\n",
        "                        'MyDrive',\n",
        "                        'Image Processing and Analysis 2022',\n",
        "                        'projects',\n",
        "                        'Calcification Detection',\n",
        "                        'dataset')\n",
        "\n",
        "DATA_PREPROCESSED = os.path.join('/content',\n",
        "                        'drive',\n",
        "                        'MyDrive',\n",
        "                        'Results',\n",
        "                        'CLAHE+Dehazing')\n",
        "\n",
        "RESULTS_DIR = os.path.join('/content',\n",
        "                        'drive',\n",
        "                        'MyDrive',\n",
        "                        'Results', \n",
        "                        'proi_files',\n",
        "                        'train-validation-test-224')\n",
        "\n",
        "\n",
        "print(os.listdir(RESULTS_DIR))\n",
        "\n",
        "results_file = os.listdir(RESULTS_DIR)\n"
      ],
      "metadata": {
        "id": "amvPAXJNDDAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "#!pip install fastprogress\n",
        "from fastprogress import master_bar, progress_bar\n",
        "import gc\n",
        "import time"
      ],
      "metadata": {
        "id": "VlzFrytQDFih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "#import plt for display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#go into de directory of the images\n",
        "\n",
        "# this have 3 outputs root directory, the folders in the path and the files in the path.\n",
        "# we ignore _ the two first because we are not interested in those\n",
        "_, _, images = next(os.walk(os.path.join(DATA_DIR,'images')))\n",
        "_, _, breastMasks = next(os.walk(os.path.join(DATA_DIR,'masks')))\n",
        "_, _, groundTruths = next(os.walk(os.path.join(DATA_DIR, 'groundtruths')))\n",
        "\n",
        "images.sort()\n",
        "breastMasks.sort()\n",
        "groundTruths.sort()\n",
        "\n",
        "# read numbers of normal images\n",
        "normals = []\n",
        "with open(os.path.join(DATA_DIR,'normals.txt')) as f:\n",
        "    for line in f:\n",
        "        normals.append(line[:-1])"
      ],
      "metadata": {
        "id": "6MRzdWcAEEJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sliding_window(image, stepSize, windowSize, groundTruth, mask):\n",
        "    # slide a window across the image\n",
        "    for y in range(0, image.shape[0], stepSize):\n",
        "        for x in range(0, image.shape[1], stepSize):\n",
        "            # yield the current window\n",
        "            # This yields the current window, label: 1 if MC and 0 if not MC, and Background: 1 if background, 0 if not background\n",
        "            yield (x, y, image[y:y + windowSize[1], x:x + windowSize[0]], str(int(np.sum(groundTruth[y:y + windowSize[1], x:x + windowSize[0]])>0)), str(int(np.sum(mask[y:y + windowSize[1], x:x + windowSize[0]])==0)))"
      ],
      "metadata": {
        "id": "IBIK-h7EDKb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sliding_window_noCentered(image, stepSize, windowSize, groundTruth, mask):\n",
        "    # slide a window across the image\n",
        "    for y in range(0, image.shape[0], stepSize):\n",
        "        for x in range(0, image.shape[1], stepSize):\n",
        "            # yield the current window\n",
        "            # This yields the current window, label: 1 if MC and 0 if not MC, and Background: 1 if background, 0 if not background, roi of the groundTruth with CC\n",
        "            yield (x, y, image[y:y + windowSize[1], x:x + windowSize[0]], str(int(np.sum(groundTruth[y:y + windowSize[1], x:x + windowSize[0]])>0)), str(int(np.sum(mask[y:y + windowSize[1], x:x + windowSize[0]])==0)), groundTruth[y:y + windowSize[1], x:x + windowSize[0]])"
      ],
      "metadata": {
        "id": "ZVxTdZZ3mFev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import pandas as pd\n",
        "\n",
        "groundTruthsDataFrame = pd.read_csv(os.path.join('/content',\n",
        "                              'drive',\n",
        "                              'MyDrive',\n",
        "                              'Results',\n",
        "                              'groundTruthStatsFinal.csv'))\n",
        "\n",
        "groundTruthsDataFrame['key']= [i.split('_')[0] for i in groundTruthsDataFrame['name'].values.tolist()]\n",
        "\n",
        "row_centroids = []\n",
        "row_areas = []\n",
        "for index, row in groundTruthsDataFrame.iterrows():\n",
        "  count = 0\n",
        "  centroids_final = []\n",
        "  areas_final = []\n",
        "  for area in eval(row['area']):\n",
        "    if (area <= np.floor(np.pi*(15/2.0)**2)):\n",
        "      areas_final.append(area)\n",
        "      centroids_final.append(eval(row['centroids'])[count])\n",
        "    count += 1\n",
        "  \n",
        "  row_centroids.append(centroids_final)\n",
        "  row_areas.append(areas_final)\n",
        "groundTruthsDataFrame['final_centroids'] = row_centroids\n",
        "groundTruthsDataFrame['final_areas'] = row_areas\n"
      ],
      "metadata": {
        "id": "P3xRakv2GdNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "groundTruthsDataFrame"
      ],
      "metadata": {
        "id": "hFQ0zhn-Sre0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# groundTruthsDataFrame.loc[groundTruthsDataFrame.final_centroids]\n",
        "normal_keys = []\n",
        "for index, row in groundTruthsDataFrame.iterrows():\n",
        "  if len(row.final_areas) == 0:\n",
        "    normal_keys.append(row.key)"
      ],
      "metadata": {
        "id": "FaH-WdkCy6Fh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal_keys_all = []\n",
        "for index, row in groundTruthsDataFrame.iterrows():\n",
        "  if (row.num_labels == 0):\n",
        "    normal_keys_all.append(row.key)"
      ],
      "metadata": {
        "id": "-Tt2MOuv6vsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal_keys = [i for i in normal_keys if i != '']\n",
        "len(normal_keys)"
      ],
      "metadata": {
        "id": "H9GhkBNU2LFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(normals)) # normals that professor gave us\n",
        "print(len(normal_keys)) # normals no calcifications and images without big calcifications\n",
        "print(len(normal_keys_all)) # normals that have something in the groundTruth (could be a big calcification)"
      ],
      "metadata": {
        "id": "hFyFdsxi2e8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_train_test = pd.read_csv(os.path.join('/content',\n",
        "                              'drive',\n",
        "                              'MyDrive',\n",
        "                              'Results',\n",
        "                              'standard_partitions.csv'), index_col=0)\n",
        "train_keys = df_train_test.loc[df_train_test.partition == 'train']['image_id'].values\n",
        "test_keys = df_train_test.loc[df_train_test.partition == 'test'].sample(frac=0.8, random_state=1)['image_id'].values\n",
        "validation_keys= [i for i in df_train_test.loc[df_train_test.partition == 'test']['image_id'].values if i not in test_keys]\n",
        "\n",
        "\n",
        "print(len(train_keys))\n",
        "print(len(validation_keys))\n",
        "print(len(test_keys))\n"
      ],
      "metadata": {
        "id": "kjNRZmOrGs2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **For non centered MCs**"
      ],
      "metadata": {
        "id": "tDrf32wSoJin"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.measure import label as label_ski\n",
        "from skimage.measure import regionprops\n",
        "\n",
        "\n",
        "windowsWH = [224]\n",
        "\n",
        "for w in windowsWH:\n",
        "  \n",
        "    winW=w\n",
        "    winH=w\n",
        "\n",
        "\n",
        "    \"\"\"    roi_width = xx; roi_height = xx; scale_factor = xx\n",
        "        <image_filename> <px> <py>\"\"\"\n",
        "\n",
        "    df_1 = pd.DataFrame(columns = [f'roi_width = {winW}', f' roi_height = {winH}', ' scale_factor = 1'])\n",
        "    df_1.to_csv(os.path.join(RESULTS_DIR, f'noMC.w{winW}.train.proi'), index=False, sep=';')\n",
        "    df_1.to_csv(os.path.join(RESULTS_DIR, f'noMC.w{winW}.validation.proi'), index=False, sep=';')\n",
        "    df_1.to_csv(os.path.join(RESULTS_DIR, f'noMC.w{winW}.test.proi'), index=False, sep=';')\n",
        "    df_1.to_csv(os.path.join(RESULTS_DIR, f'MC.w{winW}.train.proi'), index=False, sep=';')\n",
        "    df_1.to_csv(os.path.join(RESULTS_DIR, f'MC.w{winW}.validation.proi'), index=False, sep=';')\n",
        "    df_1.to_csv(os.path.join(RESULTS_DIR, f'MC.w{winW}.test.proi'), index=False, sep=';')\n",
        "\n",
        "    df_2 = pd.DataFrame(columns = ['<image_filename>', '<px>', '<py>'])\n",
        "    df_2.to_csv(os.path.join(RESULTS_DIR, f'noMC.w{winW}.train.proi'), index=False, mode='a', sep=' ')\n",
        "    df_2.to_csv(os.path.join(RESULTS_DIR, f'noMC.w{winW}.validation.proi'), index=False, mode='a', sep=' ')\n",
        "    df_2.to_csv(os.path.join(RESULTS_DIR, f'noMC.w{winW}.test.proi'), index=False, mode='a', sep=' ')\n",
        "    df_2.to_csv(os.path.join(RESULTS_DIR, f'MC.w{winW}.train.proi'), index=False, mode='a', sep=' ')\n",
        "    df_2.to_csv(os.path.join(RESULTS_DIR, f'MC.w{winW}.validation.proi'), index=False, mode='a', sep=' ')\n",
        "    df_2.to_csv(os.path.join(RESULTS_DIR, f'MC.w{winW}.test.proi'), index=False, mode='a', sep=' ')\n",
        "\n",
        "    already = []\n",
        "\n",
        "    for image, breastMask, groundTruth in zip(progress_bar(images), breastMasks, groundTruths):\n",
        "        start = time.time()\n",
        "\n",
        "        mc_list = []\n",
        "        no_mc_list = []\n",
        "\n",
        "\n",
        "        count_neg = 0\n",
        "        count_pos = 0\n",
        "        count_bkg = 0\n",
        "\n",
        "\n",
        "        # 20588020, 7717, 5328, 3787, 5725, 3859, 6934, 50995872\n",
        "        # digits = '20587372'\n",
        "\n",
        "        # if ((digits in image) and (digits in breastMask) and ('mask' in breastMask)):\n",
        "        if image.split('_')[0] not in already:\n",
        "\n",
        "            #if image not in already:\n",
        "            print(\"image: \", image)\n",
        "            #upload images\n",
        "            img = cv2.imread(os.path.join(DATA_DIR,'images',image))\n",
        "            imgMask = cv2.imread(os.path.join(DATA_DIR, 'masks', breastMask), cv2.IMREAD_GRAYSCALE)\n",
        "            imgGroundTruth = cv2.imread(os.path.join(DATA_DIR, 'groundtruths', groundTruth), cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "\n",
        "            gtRow = groundTruthsDataFrame.loc[groundTruthsDataFrame['key'] == image.split('_')[0]]\n",
        "\n",
        "            if int(image.split('_')[0]) in list(train_keys):\n",
        "              filename_MC = f'MC.w{winW}.train.proi'\n",
        "              filename_noMC = f'noMC.w{winW}.train.proi'\n",
        "            elif int(image.split('_')[0]) in list(test_keys):\n",
        "              filename_MC = f'MC.w{winW}.test.proi'\n",
        "              filename_noMC = f'noMC.w{winW}.test.proi'\n",
        "            else:\n",
        "              filename_MC = f'MC.w{winW}.validation.proi'\n",
        "              filename_noMC = f'noMC.w{winW}.validation.proi'\n",
        "            \n",
        "            blobs = imgGroundTruth > 0.7 * imgGroundTruth.mean() #Thresholding the background\n",
        "            blobs_labels, count = label_ski(blobs, background=0, return_num=True) #Getting labels of the connected components and the amount of them without considering the background\n",
        "            props = regionprops(blobs_labels)\n",
        "\n",
        "            # Label is 1 if MC and 0 in no MC. Background is  1 if background and 0 if not\n",
        "            for (x, y, window, label, background, roi_labels) in sliding_window_noCentered(img, stepSize=int(winW/2), windowSize=(winW, winH), groundTruth=blobs_labels, mask=imgMask):\n",
        "\n",
        "                if window.shape[0] != winH or window.shape[1] != winW:\n",
        "                    continue\n",
        "\n",
        "                if bool(int(background)):\n",
        "                    count_bkg += 1\n",
        "                    continue\n",
        "\n",
        "                if label == '0':\n",
        "                  no_mc_list.append([image, x, y])\n",
        "                  count_neg += 1\n",
        "\n",
        "\n",
        "                else: # unnecessary if label is 1 it will always be true\n",
        "                  # https://scikit-image.org/docs/stable/api/skimage.measure.html#skimage.measure.regionprops\n",
        "                  count = 0\n",
        "                  matching_labels = [i for i in np.unique(roi_labels) if i != 0]# not take into account background\n",
        "                  \n",
        "                  for match in matching_labels:\n",
        "                    if props[match-1].area > np.floor(np.pi*(15/2.0)**2):\n",
        "                      count+=1\n",
        "                  if count == len(matching_labels):\n",
        "                    # all matches correspond to big calcifications \n",
        "                    print('Area too big... ignored')\n",
        "                  else:\n",
        "                    mc_list.append([image, x, y])\n",
        "                    count_pos += 1 \n",
        "            print('File MC done')      \n",
        "                \n",
        "            df_mc = pd.DataFrame(mc_list,columns=['<image_filename>', '<px>', '<py>'])\n",
        "            df_mc.to_csv(os.path.join(RESULTS_DIR, filename_MC), index=False, header=False, mode='a', sep=' ')\n",
        "\n",
        "\n",
        "\n",
        "            df_no_mc = pd.DataFrame(no_mc_list,columns=['<image_filename>', '<px>', '<py>'])\n",
        "            df_no_mc.to_csv(os.path.join(RESULTS_DIR, filename_noMC), index=False, header=False,  mode='a', sep=' ')\n",
        "\n",
        "            print('File noMC done')\n",
        "\n",
        "            print('Number of backgrounds ignored: ', count_bkg)\n",
        "            print('Number of positives: ', count_pos)\n",
        "            print('Number of negatives: ', count_neg)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            del df_no_mc, img, imgMask, imgGroundTruth, window, df_mc\n",
        "            gc.collect()\n",
        "\n",
        "            print(\"Time taken for the image: \", time.time() - start)\n",
        "\n",
        "    # machine learning must be applied for the classification of the features extracted\n",
        "\n"
      ],
      "metadata": {
        "id": "qfVmCHQiiDCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **For Centered MCs**"
      ],
      "metadata": {
        "id": "bLmx80m9Uxpq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "windowsWH = [12, 24, 48, 96]\n",
        "\n",
        "for w in windowsWH:\n",
        "  \n",
        "    winW=w\n",
        "    winH=w\n",
        "\n",
        "\n",
        "    \"\"\"    roi_width = xx; roi_height = xx; scale_factor = xx\n",
        "        <image_filename> <px> <py>\"\"\"\n",
        "\n",
        "    df_1 = pd.DataFrame(columns = [f'roi_width = {winW}', f' roi_height = {winH}', ' scale_factor = 1'])\n",
        "    df_1.to_csv(os.path.join(RESULTS_DIR, f'noMC.w{winW}.train.proi'), index=False, sep=';')\n",
        "    df_1.to_csv(os.path.join(RESULTS_DIR, f'noMC.w{winW}.validation.proi'), index=False, sep=';')\n",
        "    df_1.to_csv(os.path.join(RESULTS_DIR, f'noMC.w{winW}.test.proi'), index=False, sep=';')\n",
        "    df_1.to_csv(os.path.join(RESULTS_DIR, f'MC.w{winW}.train.proi'), index=False, sep=';')\n",
        "    df_1.to_csv(os.path.join(RESULTS_DIR, f'MC.w{winW}.validation.proi'), index=False, sep=';')\n",
        "    df_1.to_csv(os.path.join(RESULTS_DIR, f'MC.w{winW}.test.proi'), index=False, sep=';')\n",
        "\n",
        "    df_2 = pd.DataFrame(columns = ['<image_filename>', '<px>', '<py>'])\n",
        "    df_2.to_csv(os.path.join(RESULTS_DIR, f'noMC.w{winW}.train.proi'), index=False, mode='a', sep=' ')\n",
        "    df_2.to_csv(os.path.join(RESULTS_DIR, f'noMC.w{winW}.validation.proi'), index=False, mode='a', sep=' ')\n",
        "    df_2.to_csv(os.path.join(RESULTS_DIR, f'noMC.w{winW}.test.proi'), index=False, mode='a', sep=' ')\n",
        "    df_2.to_csv(os.path.join(RESULTS_DIR, f'MC.w{winW}.train.proi'), index=False, mode='a', sep=' ')\n",
        "    df_2.to_csv(os.path.join(RESULTS_DIR, f'MC.w{winW}.validation.proi'), index=False, mode='a', sep=' ')\n",
        "    df_2.to_csv(os.path.join(RESULTS_DIR, f'MC.w{winW}.test.proi'), index=False, mode='a', sep=' ')\n",
        "\n",
        "    already = []\n",
        "\n",
        "    for image, breastMask, groundTruth in zip(progress_bar(images), breastMasks, groundTruths):\n",
        "        start = time.time()\n",
        "\n",
        "        mc_list = []\n",
        "        no_mc_list = []\n",
        "\n",
        "\n",
        "        count_neg = 0\n",
        "        count_pos = 0\n",
        "        count_bkg = 0\n",
        "\n",
        "\n",
        "        # 20588020, 7717, 5328, 3787, 5725, 3859, 6934, 50995872\n",
        "        # digits = '20587372'\n",
        "\n",
        "        # if ((digits in image) and (digits in breastMask) and ('mask' in breastMask)):\n",
        "        if image.split('_')[0] not in already:\n",
        "\n",
        "            #if image not in already:\n",
        "            print(\"image: \", image)\n",
        "            #upload images\n",
        "            img = cv2.imread(os.path.join(DATA_DIR,'images',image))\n",
        "            imgMask = cv2.imread(os.path.join(DATA_DIR, 'masks', breastMask), cv2.IMREAD_GRAYSCALE)\n",
        "            imgGroundTruth = cv2.imread(os.path.join(DATA_DIR, 'groundtruths', groundTruth), cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "\n",
        "            gtRow = groundTruthsDataFrame.loc[groundTruthsDataFrame['key'] == image.split('_')[0]]\n",
        "\n",
        "            if int(image.split('_')[0]) in list(train_keys):\n",
        "              filename_MC = f'MC.w{winW}.train.proi'\n",
        "              filename_noMC = f'noMC.w{winW}.train.proi'\n",
        "            elif int(image.split('_')[0]) in list(test_keys):\n",
        "              filename_MC = f'MC.w{winW}.test.proi'\n",
        "              filename_noMC = f'noMC.w{winW}.test.proi'\n",
        "            else:\n",
        "              filename_MC = f'MC.w{winW}.validation.proi'\n",
        "              filename_noMC = f'noMC.w{winW}.validation.proi'\n",
        "\n",
        "            for centroid in gtRow['final_centroids'].values[0]:\n",
        "                if ((centroid[0]+(winW/2)) < img.shape[0]) and ((centroid[1]+(winW/2)) < img.shape[1]) and ((centroid[0]-(winW/2)) > 0) and ((centroid[1]-(winW/2)) > 0):\n",
        "#                    plt.imshow(imgGroundTruth[int(centroid[0]-winW/2):int(centroid[0]+winW/2), int(centroid[1]-winW/2):int(centroid[1]+winW/2)], cmap='gray')\n",
        "                    mc_list.append([image, int(centroid[1]-winW/2), int(centroid[0]-winW/2)])\n",
        "                    count_pos += 1 \n",
        "                \n",
        "            df_mc = pd.DataFrame(mc_list,columns=['<image_filename>', '<px>', '<py>'])\n",
        "            df_mc.to_csv(os.path.join(RESULTS_DIR, filename_MC), index=False, header=False, mode='a', sep=' ')\n",
        "            \n",
        "            print('File MC done')\n",
        "\n",
        "            del df_mc\n",
        "            \n",
        "            # Label is 1 if MC and 0 in no MC. Background is  1 if background and 0 if not\n",
        "            for (x, y, window, label, background) in sliding_window(img, stepSize=int(winW/3), windowSize=(winW, winH), groundTruth=imgGroundTruth, mask=imgMask):\n",
        "                if window.shape[0] != winH or window.shape[1] != winW:\n",
        "                    continue\n",
        "\n",
        "                if bool(int(background)):\n",
        "                    count_bkg += 1\n",
        "                    continue\n",
        "\n",
        "                if label == '0':\n",
        "                  no_mc_list.append([image, x, y])\n",
        "                  count_neg += 1\n",
        "\n",
        "            df_no_mc = pd.DataFrame(no_mc_list,columns=['<image_filename>', '<px>', '<py>'])\n",
        "            df_no_mc.to_csv(os.path.join(RESULTS_DIR, filename_noMC), index=False, header=False,  mode='a', sep=' ')\n",
        "\n",
        "            print('File noMC done')\n",
        "\n",
        "            print('Number of backgrounds ignored: ', count_bkg)\n",
        "            print('Number of positives: ', count_pos)\n",
        "            print('Number of negatives: ', count_neg)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            del df_no_mc, img, imgMask, imgGroundTruth, window\n",
        "            gc.collect()\n",
        "\n",
        "            print(\"Time taken for the image: \", time.time() - start)\n",
        "\n",
        "    # machine learning must be applied for the classification of the features extracted\n",
        "\n"
      ],
      "metadata": {
        "id": "Jv2_GrtODR32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mean and standard deviation calculation"
      ],
      "metadata": {
        "id": "LgO78vjfSZtu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "\n",
        "for image, breastMask in zip(images, breastMasks):\n",
        "  if int(image.split(\"_\")[0]) in test_keys:\n",
        "    img = cv2.imread(os.path.join(DATA_PREPROCESSED,image))\n",
        "    mask = cv2.imread(os.path.join(DATA_DIR,'masks',breastMask), cv2.IMREAD_GRAYSCALE) > 0\n",
        "    maskedImg = img[mask]\n",
        "    if count == 0:\n",
        "      concatImages = maskedImg\n",
        "      count += 1\n",
        "    else:\n",
        "      concatImages = np.concatenate((concatImages, maskedImg))"
      ],
      "metadata": {
        "id": "PEY_Rj79fwPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "totalmean = np.mean(concatImages)\n",
        "totalstd = np.std(concatImages)\n",
        "print(totalmean)\n",
        "print(totalstd)"
      ],
      "metadata": {
        "id": "1lgDMIxdf4Lx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}