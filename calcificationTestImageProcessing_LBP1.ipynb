{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emyesme/CalcificationDetection/blob/Zarin/calcificationTestImageProcessing_LBP1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Wlt8za56vXZ",
        "outputId": "0c6c006a-7eda-48dc-da65-8b2c8fe9cbce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.21.5)\n"
          ]
        }
      ],
      "source": [
        "# just once to install opencv\n",
        "!pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxBuW7bh_jBI",
        "outputId": "6c470e10-4e6a-40aa-d18c-a2e22727ac51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.7)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.21.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib) (3.10.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "# just once to install matplotlib\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tsmOedaCD10",
        "outputId": "9cba0fb1-fc78-4513-f86b-aee9818147b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.5)\n"
          ]
        }
      ],
      "source": [
        "# just once to install numpy\n",
        "!pip install numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGMIWbpq7lPX"
      },
      "outputs": [],
      "source": [
        "# just once to install google.colab\n",
        "#!pip install google-colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oM9CBgTjzaM-"
      },
      "outputs": [],
      "source": [
        "#!pip install PyWavelets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cY2EJLXij72v"
      },
      "outputs": [],
      "source": [
        "#!pip install image_dehazer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RC3y6ZpI6cAh",
        "outputId": "c6f46133-7c72-4d69-cdd9-abc467410b76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (0.18.3)\n",
            "Collecting scikit-image\n",
            "  Downloading scikit_image-0.19.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (13.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.5 MB 6.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (21.3)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.4.1)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.21.5)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (7.1.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.4.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.3.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.6.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->scikit-image) (3.0.7)\n",
            "Installing collected packages: scikit-image\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.18.3\n",
            "    Uninstalling scikit-image-0.18.3:\n",
            "      Successfully uninstalled scikit-image-0.18.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed scikit-image-0.19.2\n"
          ]
        }
      ],
      "source": [
        "!pip install -U scikit-image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PcHV0uIoNFHs"
      },
      "outputs": [],
      "source": [
        "#!pip install fastprogress\n",
        "from fastprogress import master_bar, progress_bar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5i-G98GNpyYt",
        "outputId": "01416025-31a3-4d76-9c60-f060abaf2ea0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5st-OLpSqZ6A",
        "outputId": "f16a847a-1cd4-4c08-ce4c-491c03e99608"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['normals.txt', 'images', 'groundtruths', 'masks']\n"
          ]
        }
      ],
      "source": [
        "import os \n",
        "\n",
        "#first put a shortcut in your drive to the image processing folder\n",
        "\n",
        "DATA_DIR = os.path.join('/content',\n",
        "                        'drive',\n",
        "                        'MyDrive',\n",
        "                        'Image Processing and Analysis 2022',\n",
        "                        'projects',\n",
        "                        'Calcification Detection',\n",
        "                        'dataset')\n",
        "\n",
        "\n",
        "print(os.listdir(DATA_DIR))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8nkv1ToTdLO"
      },
      "outputs": [],
      "source": [
        "# os.listdir(DATA_DIR + \"/groundtruths\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jc5Lu21CF2sx"
      },
      "outputs": [],
      "source": [
        "# import opencv\n",
        "import cv2\n",
        "# import numpy\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5RUKbMaE50a"
      },
      "outputs": [],
      "source": [
        "# preprocessing\n",
        "# here explain what you code\n",
        "def preprocessingWavelet(matrix, mask):\n",
        "  # wavelet high pass, low pass or low pass, high pass, high pass high pass.\n",
        "  import pywt  \n",
        "\n",
        "  # enhancement\n",
        "  # Comparing the Performance of Image Enhancement Methods\n",
        "  # to Detect Microcalcification Clusters in Digital Mammography, Moradmand, Hajar, 2012\n",
        "\n",
        "  # Five-level   discrete   wavelet decomposition  was  employed  by  using  Asymmetric Daubechies  of  order  8; \n",
        "\n",
        "  # normal wavelet from stackoverflow\n",
        "  # convert to grayscale\n",
        "  grayscale = cv2.cvtColor(matrix, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  # convert to float\n",
        "  arrayFloat = np.float32(grayscale)\n",
        "  arrayFloat /= 255\n",
        "  \n",
        "  # compute coefficients\n",
        "  coeffs = pywt.wavedec2(arrayFloat,'haar',level=10)\n",
        "\n",
        "  #process coefficients\n",
        "  coeffs_H = list(coeffs)\n",
        "  coeffs_H[0] *= 0\n",
        "\n",
        "  # reconstruction\n",
        "  arrayFloat_H = pywt.waverec2(coeffs_H, 'haar')\n",
        "  arrayFloat_H *= 255\n",
        "  arrayFloat_H = np.uint8(arrayFloat_H)\n",
        "\n",
        "  preprocessed = arrayFloat_H\n",
        "  return preprocessed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cJXfvTTks38"
      },
      "outputs": [],
      "source": [
        "# preprocessing\n",
        "# here explain what you code\n",
        "def preprocessingDeHazingPy(matrix, mask):\n",
        "  # https://link.springer.com/chapter/10.1007/978-3-319-68548-9_27\n",
        "  # the professor say we can take the grays in the mammogram as haze. so use dehazing\n",
        "\n",
        "  # still no the hazing method that he use this is just one found in a python library\n",
        "  # https://github.com/Utkarsh-Deshmukh/Single-Image-Dehazing-Python\n",
        "  # dehazing\n",
        "\n",
        "  import image_dehazer\t# Load the library\n",
        "\n",
        "  hazeCorrectedImg = image_dehazer.remove_haze(matrix)\t\t# Remove Haze\n",
        "\n",
        "  preprocessed = hazeCorrectedImg\n",
        "  return preprocessed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9lVjTTcoC2C"
      },
      "outputs": [],
      "source": [
        "# dehaze single image using dark channel prior and guided filter\n",
        "# taken from a repository \n",
        "# https://github.com/He-Zhang/image_dehaze\n",
        "# dehazing method proposed by the professor \n",
        "# simple imaging dehazing using dark channel prior (and guided filter, readme.md of the repo say that)\n",
        "import math\n",
        "\n",
        "# change this methods to do just grayscale will be nice\n",
        "\n",
        "def DarkChannel(im,sz):\n",
        "    b,g,r = cv2.split(im)\n",
        "    dc = cv2.min(cv2.min(r,g),b);\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(sz,sz))\n",
        "    dark = cv2.erode(dc,kernel)\n",
        "    return dark\n",
        "\n",
        "def AtmLight(im,dark):\n",
        "    [h,w] = im.shape[:2]\n",
        "    imsz = h*w\n",
        "    numpx = int(max(math.floor(imsz/1000),1))\n",
        "    darkvec = dark.reshape(imsz);\n",
        "    imvec = im.reshape(imsz,3);\n",
        "\n",
        "    indices = darkvec.argsort();\n",
        "    indices = indices[imsz-numpx::]\n",
        "\n",
        "    atmsum = np.zeros([1,3])\n",
        "    for ind in range(1,numpx):\n",
        "       atmsum = atmsum + imvec[indices[ind]]\n",
        "\n",
        "    A = atmsum / numpx;\n",
        "    return A\n",
        "\n",
        "def TransmissionEstimate(im,A,sz):\n",
        "    omega = 0.95;\n",
        "    im3 = np.empty(im.shape,im.dtype);\n",
        "\n",
        "    for ind in range(0,3):\n",
        "        im3[:,:,ind] = im[:,:,ind]/A[0,ind]\n",
        "\n",
        "    transmission = 1 - omega*DarkChannel(im3,sz);\n",
        "    return transmission\n",
        "\n",
        "def Guidedfilter(im,p,r,eps):\n",
        "    mean_I = cv2.boxFilter(im,cv2.CV_64F,(r,r));\n",
        "    mean_p = cv2.boxFilter(p, cv2.CV_64F,(r,r));\n",
        "    mean_Ip = cv2.boxFilter(im*p,cv2.CV_64F,(r,r));\n",
        "    cov_Ip = mean_Ip - mean_I*mean_p;\n",
        "\n",
        "    mean_II = cv2.boxFilter(im*im,cv2.CV_64F,(r,r));\n",
        "    var_I   = mean_II - mean_I*mean_I;\n",
        "\n",
        "    a = cov_Ip/(var_I + eps);\n",
        "    b = mean_p - a*mean_I;\n",
        "\n",
        "    mean_a = cv2.boxFilter(a,cv2.CV_64F,(r,r));\n",
        "    mean_b = cv2.boxFilter(b,cv2.CV_64F,(r,r));\n",
        "\n",
        "    q = mean_a*im + mean_b;\n",
        "    return q;\n",
        "\n",
        "def TransmissionRefine(im,et):\n",
        "    gray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY);\n",
        "    gray = np.float64(gray)/255;\n",
        "    r = 60;\n",
        "    eps = 0.0001;\n",
        "    t = Guidedfilter(gray,et,r,eps);\n",
        "\n",
        "    return t;\n",
        "\n",
        "def Recover(im,t,A,tx = 0.1):\n",
        "    res = np.empty(im.shape,im.dtype);\n",
        "    t = cv2.max(t,tx);\n",
        "\n",
        "    for ind in range(0,3):\n",
        "        res[:,:,ind] = (im[:,:,ind]-A[0,ind])/t + A[0,ind]\n",
        "    return res\n",
        "\n",
        "def deHazingDarkChannelPriorPy(matrix, mask):\n",
        "\n",
        "    I = matrix.astype(np.float64)/255\n",
        " \n",
        "    dark = DarkChannel(I,15)\n",
        "    A = AtmLight(I,dark)\n",
        "    te = TransmissionEstimate(I,A,15)\n",
        "    t = TransmissionRefine(matrix,te)\n",
        "    J = Recover(I,t,A,0.1)\n",
        "    preprocessed = J\n",
        "    return preprocessed\n",
        "\n",
        "# image = cv2.imread(DATA_DIR+\"/images/53582422_3f0db31711fc9795_MG_R_ML_ANON.tif\")\n",
        "# dark, t, matrix, J = deHazingDarkChannelPriorPy(image, image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0KHFD9fFC9y"
      },
      "outputs": [],
      "source": [
        "# candidateExtraction\n",
        "# here explain what you code\n",
        "# Hessian-matrix-based analysis or difference of gaussians (DoH) blob detection from skimage\n",
        "# https://scikit-image.org/docs/stable/api/skimage.feature.html?highlight=local%20binary%20pattern#skimage.feature.blob_doh\n",
        "def candidateExtraction(matrix, mask):\n",
        "\n",
        "  from skimage import feature\n",
        "\n",
        "  # returns x,y,sigma of the blob\n",
        "  blobs = feature.blob_doh(matrix,\n",
        "                           min_sigma=1,\n",
        "                           max_sigma=30,\n",
        "                           num_sigma=10,\n",
        "                           # The absolute lower bound for scale space maxima.\n",
        "                           # Local maxima smaller than threshold are ignored.\n",
        "                           # Reduce this to detect blobs with lower intensities.\n",
        "                           # If threshold_rel is also specified, whichever threshold is larger will be used.\n",
        "                           # If None, threshold_rel is used instead.\n",
        "                           threshold=0.005,\n",
        "                           # lower more sensible, more false positives bad also tinier calcifications detected\n",
        "                           overlap=0.5,\n",
        "                           log_scale=False,\n",
        "                           threshold_rel=None\n",
        "                           )\n",
        "  # taken from the documentation\n",
        "  # ...The downside is that this method can’t be used for detecting blobs of radius less than 3px\n",
        "  # due to the box filters used in the approximation of Hessian Determinant.\n",
        "  result = blobs\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23WbyaI2FhzF"
      },
      "outputs": [],
      "source": [
        "# # featuresExtraction\n",
        "# # here explain what you code\n",
        "# def featuresExtraction(matrix, candidates, features, mask):\n",
        "  \n",
        "#   # distances\n",
        "#   # taking into account the microcalcifications can be less that 5 pixels\n",
        "#   # distances should vary with that\n",
        "#   distances = [1, 3, 5, 7]# probably we need bigger\n",
        "#   # angles\n",
        "#   #         0     45      90       135\n",
        "#   angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
        "\n",
        "\n",
        "#   # patches\n",
        "#   patches = []\n",
        "#   for candidate in candidates:\n",
        "#     # candidate points are save as np.float64\n",
        "#     # to use them as coordinates they have to be integers\n",
        "#     candidate = candidate.astype(np.int64)\n",
        "#     # candidates are x,y and sigma\n",
        "#     patchCandidate = matrix[candidate[0]:candidate[0] + candidate[2],\n",
        "#                             candidate[1]:candidate[1] + candidate[2]]\n",
        "\n",
        "#     # reduce even more the shades of gray T-T\n",
        "#     # graycomatrix, glcm, receive unsigned integer type\n",
        "#     # but if it is bigger that np.uint8 you have to change the levels argument\n",
        "#     # of graycomatrix for the shades of gray, if it is np.uint16, levels shoud be\n",
        "#     # aprox 65 535. that break the colab :c \n",
        "#     patchCandidate = patchCandidate.astype(np.uint8)\n",
        "#     # add to the list\n",
        "#     patches.append(patchCandidate)\n",
        "  \n",
        "#   # https://www.youtube.com/watch?v=5x-CIHRmMNY\n",
        "#   # https://scikit-image.org/docs/dev/auto_examples/features_detection/plot_glcm.html\n",
        "#   # https://ijcrr.com/uploads/3454_pdf.pdf\n",
        "\n",
        "#   from skimage import feature\n",
        "#   import itertools\n",
        "#   # combination of distances and angles as couples of values\n",
        "#   distancesAngles = list(itertools.product(distances, angles))\n",
        "\n",
        "#   for patch in patches:\n",
        "#     for distanceAngle in distancesAngles:\n",
        "#       distance = distanceAngle[0]\n",
        "#       angle = distanceAngle[1]\n",
        "#       # get the degree to use it as name for the column\n",
        "#       name = str(angle*(180.0/np.pi))\n",
        "#       # input image, distance in pixels, angles\n",
        "#       glcm = feature.graycomatrix(patch, [ distance ], [ angle ])\n",
        "#       # Output: the gray-level co-occurrence histogram. The value P[i,j,d,theta]\n",
        "#       # is the number of times that gray-level j occurs at a distance d\n",
        "#       # and at an angle theta from gray-level i.\n",
        "#       # If normed is False, the output is of type uint32, otherwise it is float64.\n",
        "#       # The dimensions are: levels x levels x number of distances x number of angles.\n",
        "\n",
        "#       # properties: {‘contrast’, ‘dissimilarity’, ‘homogeneity’, ‘energy’, ‘correlation’, ‘ASM’}\n",
        "#       features['contrast'+ str(distance) + name] = feature.graycoprops(glcm, 'contrast')[0]\n",
        "#       features['dissimilarity' + str(distance) + name] = feature.graycoprops(glcm, 'dissimilarity')[0]\n",
        "#       features['homogeneity' + str(distance) + name] = feature.graycoprops(glcm, 'homogeneity')[0]\n",
        "#       features['energy' + str(distance) + name] = feature.graycoprops(glcm, 'energy')[0]\n",
        "#       features['correlation' + str(distance) + name] = feature.graycoprops(glcm, 'correlation')[0]\n",
        "#       features['ASM' + str(distance) + name] = feature.graycoprops(glcm, 'ASM')[0]\n",
        "\n",
        "#       # print('contrast ', features['contrast'+ str(distance) + name])\n",
        "#       # print('dissimilarity ', features['dissimilarity' + str(distance) + name])\n",
        "#       # print('homogeneity ', features['homogeneity' + str(distance) + name])\n",
        "#       # print('energy ', features['energy' + str(distance) + name])\n",
        "#       # print('correlation ', features['correlation' + str(distance) + name])\n",
        "#       # print('asm ', features['ASM' + str(distance) + name])\n",
        "#       if ((distance  == 5) and (angle == 3*np.pi/4)):\n",
        "      \n",
        "#         print('creation')\n",
        "#         print(feature.graycoprops(glcm, 'contrast'))\n",
        "\n",
        "#       # https://scikit-image.org/docs/dev/api/skimage.feature.html#skimage.feature.graycoprops\n",
        "#       # Compute a feature of a gray level co-occurrence matrix to serve as a compact summary of the matrix.\n",
        "#       # The properties are computed as follows:\n",
        "#       # contrast\n",
        "#       # dissimilarity\n",
        "#       # homogeneity\n",
        "#       # ASM\n",
        "#       # energy\n",
        "\n",
        "#   print('function')\n",
        "#   print('value ', features['contrast5135'])\n",
        "\n",
        "#   return features\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# featuresExtraction\n",
        "# Local Binary Pattern + GLCM statistical feature set for feature extraction\n",
        "# Sadad T, Munir A, Saba T, Hussain A, Fuzzy C-Means and Region Growing based Classification of Tumor from Mammograms using Hybrid Texture Features, Journal of Computational Science (2018),\n",
        "# https://doi.org/10.1016/j.jocs.2018.09.015\n",
        "\n",
        "def featuresExtractionLBP(matrix, candidates, featuresLBP, mask):\n",
        "  \n",
        "  # distances\n",
        "  # taking into account the microcalcifications can be less that 5 pixels\n",
        "  # distances should vary with that\n",
        "  distances = [1, 3, 5, 7]# probably we need bigger\n",
        "  # angles\n",
        "  #         0     45      90       135\n",
        "  angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
        "\n",
        "\n",
        "  # patches\n",
        "  patches = []\n",
        "  for candidate in candidates:\n",
        "    # candidate points are save as np.float64\n",
        "    # to use them as coordinates they have to be integers\n",
        "    candidate = candidate.astype(np.int64)\n",
        "    # candidates are x,y and sigma\n",
        "    patchCandidate = matrix[candidate[0]:candidate[0] + candidate[2],\n",
        "                            candidate[1]:candidate[1] + candidate[2]]\n",
        "\n",
        "    # reduce even more the shades of gray T-T\n",
        "    # graycomatrix, glcm, receive unsigned integer type\n",
        "    # but if it is bigger that np.uint8 you have to change the levels argument\n",
        "    # of graycomatrix for the shades of gray, if it is np.uint16, levels shoud be\n",
        "    # aprox 65 535. that break the colab :c \n",
        "    patchCandidate = patchCandidate.astype(np.uint8)\n",
        "    # add to the list\n",
        "    patches.append(patchCandidate)\n",
        "  \n",
        "  # https://www.youtube.com/watch?v=5x-CIHRmMNY\n",
        "  # https://scikit-image.org/docs/dev/auto_examples/features_detection/plot_glcm.html\n",
        "  # https://ijcrr.com/uploads/3454_pdf.pdf\n",
        "\n",
        "  from skimage import feature\n",
        "  import itertools\n",
        "  # combination of distances and angles as couples of values\n",
        "  distancesAngles = list(itertools.product(distances, angles))\n",
        "\n",
        "  for patch in patches:\n",
        "    for distanceAngle in distancesAngles:\n",
        "\n",
        "      # LBP\n",
        "      #https://scikit-image.org/docs/dev/auto_examples/features_detection/plot_local_binary_pattern.html\n",
        "      #https://scikit-image.org/docs/dev/api/skimage.feature.html#skimage.feature.local_binary_pattern\n",
        "\n",
        "      radius= 1\n",
        "      points= 8 * radius\n",
        "\n",
        "      \n",
        "      patchLBP = local_binary_pattern(patch, points, radius, method='default')      \n",
        "\n",
        "      # GLCM from LBP\n",
        "      \n",
        "\n",
        "      distance = distanceAngle[0]\n",
        "      angle = distanceAngle[1]\n",
        "      # get the degree to use it as name for the column\n",
        "      name = str(angle*(180.0/np.pi))\n",
        "      # input image, distance in pixels, angles\n",
        "      glcm = feature.graycomatrix(patchLBP, [ distance ], [ angle ])\n",
        "      # Output: the gray-level co-occurrence histogram. The value P[i,j,d,theta]\n",
        "      # is the number of times that gray-level j occurs at a distance d\n",
        "      # and at an angle theta from gray-level i.\n",
        "      # If normed is False, the output is of type uint32, otherwise it is float64.\n",
        "      # The dimensions are: levels x levels x number of distances x number of angles.\n",
        "\n",
        "      # properties: {‘contrast’, ‘dissimilarity’, ‘homogeneity’, ‘energy’, ‘correlation’, ‘ASM’}\n",
        "      featuresLBP['contrast'+ str(distance) + name] = feature.graycoprops(glcm, 'contrast')[0]\n",
        "      featuresLBP['dissimilarity' + str(distance) + name] = feature.graycoprops(glcm, 'dissimilarity')[0]\n",
        "      featuresLBP['homogeneity' + str(distance) + name] = feature.graycoprops(glcm, 'homogeneity')[0]\n",
        "      featuresLBP['energy' + str(distance) + name] = feature.graycoprops(glcm, 'energy')[0]\n",
        "      featuresLBP['correlation' + str(distance) + name] = feature.graycoprops(glcm, 'correlation')[0]\n",
        "      featuresLBP['ASM' + str(distance) + name] = feature.graycoprops(glcm, 'ASM')[0]\n",
        "\n",
        "      # print('contrast ', features['contrast'+ str(distance) + name])\n",
        "      # print('dissimilarity ', features['dissimilarity' + str(distance) + name])\n",
        "      # print('homogeneity ', features['homogeneity' + str(distance) + name])\n",
        "      # print('energy ', features['energy' + str(distance) + name])\n",
        "      # print('correlation ', features['correlation' + str(distance) + name])\n",
        "      # print('asm ', features['ASM' + str(distance) + name])\n",
        "      if ((distance  == 5) and (angle == 3*np.pi/4)):\n",
        "      \n",
        "        print('creation')\n",
        "        print(feature.graycoprops(glcm, 'contrast'))\n",
        "\n",
        "      # https://scikit-image.org/docs/dev/api/skimage.feature.html#skimage.feature.graycoprops\n",
        "      # Compute a feature of a gray level co-occurrence matrix to serve as a compact summary of the matrix.\n",
        "      # The properties are computed as follows:\n",
        "      # contrast\n",
        "      # dissimilarity\n",
        "      # homogeneity\n",
        "      # ASM\n",
        "      # energy\n",
        "\n",
        "  print('function')\n",
        "  print('value ', featuresLBP['contrast5135'])\n",
        "\n",
        "  return featuresLBP\n",
        "\n"
      ],
      "metadata": {
        "id": "SEUOrzSwsss5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7G2psxqargQ"
      },
      "outputs": [],
      "source": [
        "# function to get connected components of the ground truth binary image\n",
        "def componentsStatsGroundTruth(matrix):\n",
        "    # getting the info of the components in the ground truth\n",
        "    # second value is connectivity 4 or 8\n",
        "    connectedComponentsGroundTruth = cv2.connectedComponentsWithStats(matrix, 8, cv2.CV_32S)\n",
        "\n",
        "    # Get the results\n",
        "    # The first cell is the number of labels\n",
        "    num_labels = connectedComponentsGroundTruth[0]\n",
        "    # The second cell is the label matrix\n",
        "    labels = connectedComponentsGroundTruth[1]\n",
        "    # The third cell is the stat matrix\n",
        "    stats = connectedComponentsGroundTruth[2]\n",
        "    # The fourth cell is the centroid matrix\n",
        "    centroids = connectedComponentsGroundTruth[3]\n",
        "\n",
        "    return num_labels, labels, stats, centroids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAXteeoxLM_z"
      },
      "outputs": [],
      "source": [
        "#import show special for google colab\n",
        "from google.colab.patches import cv2_imshow\n",
        "#import plt for display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#go into de directory of the images\n",
        "\n",
        "# this have 3 outputs root directory, the folders in the path and the files in the path.\n",
        "# we ignore _ the two first because we are not interested in those\n",
        "_, _, images = next(os.walk(os.path.join(DATA_DIR,'images')))\n",
        "_, _, breastMasks = next(os.walk(os.path.join(DATA_DIR,'masks')))\n",
        "_, _, groundTruths = next(os.walk(os.path.join(DATA_DIR, 'groundtruths')))\n",
        "\n",
        "images.sort()\n",
        "breastMasks.sort()\n",
        "groundTruths.sort()\n",
        "\n",
        "# read numbers of normal images\n",
        "normals = []\n",
        "with open(os.path.join(DATA_DIR,'normals.txt')) as f:\n",
        "    for line in f:\n",
        "        normals.append(line[:-1])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "gGhsM747LRj7",
        "outputId": "a8fe486c-9d38-4c56-a65b-a54cc2b4a089"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "function ClickConnect(){\n",
              "console.log(\"Working\");\n",
              "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
              "}setInterval(ClickConnect,60000)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# https://medium.com/@robertbracco1/configuring-google-colab-like-a-pro-d61c253f7573#a642\n",
        "%%javascript\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\");\n",
        "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "}setInterval(ClickConnect,60000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6mejNA1fgIq"
      },
      "outputs": [],
      "source": [
        "from matplotlib.patches import Circle\n",
        "\n",
        "# function to draw the grid to display\n",
        "def display_grid(figure, axis, img, imgGroundTruth, preprocessed, candidates, features):\n",
        "  # draw in the axis the img\n",
        "  axis[0][0].imshow(img)\n",
        "  # switch off the axis of the plot\n",
        "  axis[0][0].axis('off')\n",
        "  # set a title for the plot\n",
        "  axis[0][0].set_title('Image')\n",
        "\n",
        "  axis[0][1].imshow(imgGroundTruth, cmap='gray')\n",
        "  axis[0][1].axis('off')\n",
        "  axis[0][1].set_title('Ground Truth')\n",
        "\n",
        "  axis[0][2].imshow(imgMask)\n",
        "  axis[0][2].axis('off')\n",
        "  axis[0][2].set_title('Breast Mask')\n",
        "\n",
        "  axis[1][0].imshow(preprocessed, cmap='gray')\n",
        "  axis[1][0].axis('off')\n",
        "  axis[1][0].set_title('Preprocessed')\n",
        "\n",
        "  # draw candidates as circles\n",
        "  axis[1][1].imshow(preprocessed, cmap='gray')\n",
        "  axis[1][1].axis('off')\n",
        "  axis[1][1].set_title('Candidates')\n",
        "\n",
        "  # Now, loop through coord arrays, and create a circle at each x,y pair\n",
        "  for y,x,sigma in candidates:\n",
        "    blob = Circle((x,y), sigma*5, color='blue', fill=False)\n",
        "    axis[1][1].add_patch(blob)\n",
        "\n",
        "  axis[1][2].imshow(imgGroundTruth, cmap='gray')\n",
        "  axis[1][2].axis('off')\n",
        "  axis[1][2].set_title('compare with ground truth and candidates')\n",
        "\n",
        "  # Now, loop through coord arrays, and create a circle at each x,y pair\n",
        "  for y,x,sigma in candidates:\n",
        "    blob = Circle((x,y), sigma, color='blue', fill=False)\n",
        "    axis[1][2].add_patch(blob)\n",
        "  \n",
        "  return figure, axis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQXTnel9jwgS",
        "outputId": "ff77c248-9c3f-47d0-b1e7-97a185cee0d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qqqX2PGi6-X8",
        "outputId": "9ba37b76-f654-4afb-c8c9-3120b0d32949"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='73' class='' max='410' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      17.80% [73/410 00:00<00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "creation\n",
            "[[0.25]]\n",
            "creation\n",
            "[[0.4691358]]\n",
            "creation\n",
            "[[0.05325444]]\n",
            "creation\n",
            "[[0.13609467]]\n",
            "creation\n",
            "[[0.11111111]]\n",
            "creation\n",
            "[[0.01234568]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.1640625]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.2265625]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.17948718]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "creation\n",
            "[[0.]]\n",
            "function\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'contrast5135'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-1898f97e7321>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;31m# feature extraction #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeaturesExtraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopyPreprocessed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgMask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-82-9ae439337c82>\u001b[0m in \u001b[0;36mfeaturesExtraction\u001b[0;34m(matrix, candidates, features, mask)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'function'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'value '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'contrast5135'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'contrast5135'"
          ]
        }
      ],
      "source": [
        "import copy\n",
        "import pandas as pd\n",
        "\n",
        "# to save the features generated with the glcm\n",
        "\n",
        "# LBP+GLCM\n",
        "# features = pd.DataFrame(dtype=np.float64)\n",
        "\n",
        "featuresLBP = pd.DataFrame(dtype=np.float64)\n",
        "\n",
        "#go through the image files \n",
        "for image, breastMask, groundTruth in zip(progress_bar(images), breastMasks, groundTruths):\n",
        "  # choose one\n",
        "  # this are the last 4 of the number of the image name {numbers}_{}_{}_{}_{}_{}.tif\n",
        "  # i suppose those are unique\n",
        "  # if your code is working try other images!\n",
        "  #print(breastMask)\n",
        "  \n",
        "  # restart variables for memory\n",
        "  # to save the candidates\n",
        "  blobs = {}\n",
        "  # to sabe the ground truth connected components\n",
        "  groundTruthsComponents = {}\n",
        "  \n",
        "\n",
        "  # 20588020, 7717, 5328, 3787, 5725, 3859, 6934, 50995872\n",
        "  digits = '24055328'\n",
        "\n",
        "  if ((digits in image) and (digits in breastMask) and ('mask' in breastMask)):\n",
        "  #if ('mask' in breastMask):\n",
        "\n",
        "    #upload images\n",
        "    img = cv2.imread(os.path.join(DATA_DIR,'images',image))\n",
        "    imgMask = cv2.imread(os.path.join(DATA_DIR, 'masks', breastMask))\n",
        "    imgGroundTruth = cv2.imread(os.path.join(DATA_DIR, 'groundtruths', image), cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "\n",
        "    # processing necessary for evaluation\n",
        "\n",
        "    # Get components of the ground truth\n",
        "    '''\n",
        "    num_labels, labels, stats, centroids = componentsStatsGroundTruth(imgGroundTruth)\n",
        "    groundTruthsComponents[image] = {}\n",
        "    groundTruthsComponents[image]['num_labels'] = num_labels\n",
        "    groundTruthsComponents[image]['labels'] = labels\n",
        "    groundTruthsComponents[image]['stats'] = stats\n",
        "    groundTruthsComponents[image]['centroids'] = centroids\n",
        "    '''\n",
        "    # preprocessing #\n",
        "\n",
        "    imgCopy = copy.deepcopy(img)\n",
        "\n",
        "    # preprocessed = preprocessingDeHazingPy(img, imgMask)\n",
        "    preprocessed = deHazingDarkChannelPriorPy(imgCopy, imgMask)\n",
        "    # after preprocessingDeHazingPy + contrast streching to see\n",
        "    # preprocessed = preprocessingDeHazingPy(imgCopy,imgMask)\n",
        "\n",
        "      # still missing quantum noise supression\n",
        "      # details in the phd defense file\n",
        "\n",
        "      # still missing linear streching\n",
        "        # keep going forever the code, computational cost\n",
        "\n",
        "      # still missing CLAHE (adaptive histogram equalization) opencv library\n",
        "        # CLAHE + dehazing bad results.\n",
        "        # points less visible with CLAHE\n",
        "\n",
        "        # dehazing + CLAHE \n",
        "        # black image\n",
        "\n",
        "      # Observations from the results:\n",
        "\n",
        "        # fiber intersections may also appear as bright spots (false positives)\n",
        "\n",
        "      # THINGS WE NOTICE BETWEEN BOTH DEHAZING METHODS\n",
        "\n",
        "        # Better suppression of fatty tissue (noise) and greater enhancement of brightness of desired feature (microcalcifications)\n",
        "\n",
        "        # sometimes for the other dehazing method black patches become present in the fatty tissue\n",
        "        # this did not happen in the dehazing with dark channel prior (and guided filter)\n",
        "\n",
        "        # sharper\n",
        "\n",
        "        # enhance the contrast\n",
        "\n",
        "        # details were enhanced\n",
        "\n",
        "    # candidate extraction #\n",
        "\n",
        "    copyPreprocessed = copy.deepcopy(preprocessed)\n",
        "\n",
        "    # we have to change np.float64 to np.float32 for the grayscale conversion\n",
        "    # leading to a reduction of gray values\n",
        "    copyPreprocessed = copyPreprocessed.astype(np.float32)\n",
        "    copyPreprocessed = cv2.cvtColor(copyPreprocessed, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    candidates = candidateExtraction(copyPreprocessed, imgMask)\n",
        "\n",
        "    # Observations from the results:\n",
        "\n",
        "      # images with pectoral muscule cause false positives\n",
        "\n",
        "    # feature extraction #\n",
        "\n",
        "    # features = featuresExtractionLBP(copyPreprocessed, candidates, features, imgMask)\n",
        "    # features['names'] = str(image)\n",
        "    featuresLBP = featuresExtractionLBP(copyPreprocessed, candidates, featuresLBP, imgMask)\n",
        "    featuresLBP['names'] = str(image)\n",
        "    print(str(image))\n",
        "    print('main')\n",
        "    print('value ', featuresLBP['contrast5135'])\n",
        "\n",
        "    # print('value ', features['contrast5135'])\n",
        "\n",
        "    # features.to_csv(os.path.join('/content',\n",
        "    #                              'drive',\n",
        "    #                              'MyDrive',\n",
        "    #                              'Results',\n",
        "    #                              'features.csv'),\n",
        "    #                 mode='a',\n",
        "    #                 index=False,\n",
        "    #                 header=False)\n",
        "    \n",
        "    # machine learning must be applied for the classification of the features extracted\n",
        "\n",
        "    # import gc\n",
        "\n",
        "    # del features\n",
        "    # del preprocessed\n",
        "    # del candidates\n",
        "    # del blobs\n",
        "    # del copyPreprocessed\n",
        "    # del imgCopy\n",
        "    # del img\n",
        "    # del imgMask\n",
        "    # del imgGroundTruth\n",
        "    \n",
        "    # gc.collect()\n",
        "    \n",
        "    # end image processing part #\n",
        "\n",
        "    # processing necessary for evaluation #\n",
        "\n",
        "    # save blobs results to check groundtruth\n",
        "    #blobs[image] = candidates\n",
        "\n",
        "\n",
        "    # display related #\n",
        "\n",
        "    # matrix of plots and size of the figure\n",
        "    figure, axis = plt.subplots(2, 3, figsize=(15,15))\n",
        "\n",
        "    #display_grid(figure, axis, img, imgGroundTruth, preprocessed, candidates, features)\n",
        "\n",
        "    plt.subplots_adjust(wspace=0, hspace=0)\n",
        "\n",
        "    # display figure with image\n",
        "    #plt.show()\n",
        "\n",
        "    # display image with other function\n",
        "    #cv2_imshow(features)\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YxtDuR3reuX"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(columns=['names'])\n",
        "\n",
        "#go through the image files \n",
        "for image, breastMask, groundTruth in zip(progress_bar(images), breastMasks, groundTruths):\n",
        "\n",
        "  #if ((digits in image) and (digits in breastMask) and ('mask' in breastMask)):\n",
        "  if ('mask' in breastMask):\n",
        "    \n",
        "    df = df.append({'names': image}, ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQYG-9Qg4yvg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "featuresLBP = pd.read_csv(os.path.join('/content',\n",
        "                        'drive',\n",
        "                        'MyDrive',\n",
        "                        'Results',\n",
        "                        'names.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVP2PHW9E66x"
      },
      "outputs": [],
      "source": [
        "\n",
        "df.to_csv( os.path.join('/content',\n",
        "                        'drive',\n",
        "                        'MyDrive',\n",
        "                        'Results',\n",
        "                        'names.csv'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Gag035mepoZ"
      },
      "outputs": [],
      "source": [
        "# save images\n",
        "'''\n",
        "cv2.imwrite(os.path.join('/content',\n",
        "                        'drive',\n",
        "                        'MyDrive',\n",
        "                        'Results',\n",
        "                         'features.csv'),\n",
        "            features)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJrrb3dxTR6P"
      },
      "outputs": [],
      "source": [
        "# evaluation froc curve #\n",
        "\n",
        "''''\n",
        "fp = 0 # false positive, findings on normal images, don't forget the normals variable\n",
        "tp = 0 # true positive, for the blobs that are inside a component\n",
        "fn = 0 # false negative, for the blobs that do not belong to any component\n",
        "\n",
        "for key in groundTruthsComponents:\n",
        "  # list of features found with y,x and sigma\n",
        "  featuresImg = blobs[key]\n",
        "  \n",
        "  # restart the variables\n",
        "  fp = 0\n",
        "  tp = 0\n",
        "  fn = 0\n",
        "\n",
        "  # is the image a normal image?\n",
        "  if (key in normals):\n",
        "    # if it is false positive\n",
        "    fp = fp + 1\n",
        "    continue\n",
        "\n",
        "  # if it is not register as normal\n",
        "  # stat have 5 items: leftmost x coordinate,\n",
        "  #                    topmost y coordinate,\n",
        "  #                    horizontal size of the bounding box\n",
        "  #                    vertical size of the bounding box\n",
        "  #                    total area in pixels of the connected component\n",
        "  for centroid, stat in zip(groundTruthsComponents[key]['centroids'], groundTruthsComponents[key]['stats']):\n",
        "    # remember one component is the background\n",
        "    \n",
        "    if (stat[0] == 0):\n",
        "      # is the background\n",
        "      continue\n",
        "\n",
        "    # top left is the 0,0 of the image\n",
        "    \n",
        "    topX = stat[0]\n",
        "    bottomX = stat[0] + stat[2]\n",
        "\n",
        "    topY = stat[1]\n",
        "    bottomY = stat[1] + stat[3]\n",
        "\n",
        "    matchs = [1 for feature in featuresImg if (( feature[1] >= topX ) and\n",
        "                                               ( feature[1] <= bottomX ) and\n",
        "                                               ( feature[0] >= topY ) and\n",
        "                                               ( feature[0] <= bottomY )) ]\n",
        "\n",
        "    # true positives\n",
        "    tp = tp + np.sum(matchs)\n",
        "\n",
        "\n",
        "    #false negatives will be the difference between the total true positives and the blobs that we receive\n",
        "\n",
        "  fn = len(featuresImg) - tp\n",
        "\n",
        "  # save and compute tpr and fpr\n",
        "\n",
        "  # to make te roc curve i need scores... clasification :|\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uo57LPvjVEEf"
      },
      "outputs": [],
      "source": [
        "\n",
        "features.to_csv( os.path.join('/content',\n",
        "                        'drive',\n",
        "                        'MyDrive',\n",
        "                        'Results',\n",
        "                        'featuresLBP.csv'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6B64-S9blVud"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "calcificationTestImageProcessing_LBP1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}