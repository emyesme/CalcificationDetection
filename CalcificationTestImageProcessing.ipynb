{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emyesme/CalcificationDetection/blob/feature-pm/CalcificationTestImageProcessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5KF-GomVYsN"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Wlt8za56vXZ",
        "outputId": "47c67078-aab9-4477-92f9-cccac0dc4906"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "# just once to install opencv\n",
        "!pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxBuW7bh_jBI",
        "outputId": "b6637ab0-95dc-4fba-f862-730fecd78045"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.21.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.8)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "# just once to install matplotlib\n",
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tsmOedaCD10",
        "outputId": "4cecd015-9c7e-472e-c374-485171fc71f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "# just once to install numpy\n",
        "!pip install numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGMIWbpq7lPX"
      },
      "outputs": [],
      "source": [
        "# just once to install google.colab\n",
        "#!pip install google-colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oM9CBgTjzaM-"
      },
      "outputs": [],
      "source": [
        "#!pip install PyWavelets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cY2EJLXij72v"
      },
      "outputs": [],
      "source": [
        "#!pip install image_dehazer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RC3y6ZpI6cAh",
        "outputId": "1674f2cb-bb19-44dd-a048-469100b354a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (0.18.3)\n",
            "Collecting scikit-image\n",
            "  Downloading scikit_image-0.19.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (13.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.5 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.4.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (7.1.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.4.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2021.11.2)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.6.3)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->scikit-image) (3.0.8)\n",
            "Installing collected packages: scikit-image\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.18.3\n",
            "    Uninstalling scikit-image-0.18.3:\n",
            "      Successfully uninstalled scikit-image-0.18.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed scikit-image-0.19.2\n"
          ]
        }
      ],
      "source": [
        "!pip install -U scikit-image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PcHV0uIoNFHs"
      },
      "outputs": [],
      "source": [
        "#!pip install fastprogress\n",
        "from fastprogress import master_bar, progress_bar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5i-G98GNpyYt",
        "outputId": "544ca48f-9028-4fd8-b2d1-a93ba499b8c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5st-OLpSqZ6A",
        "outputId": "fa042bd2-8eb1-435e-8f4f-eab172a8ab0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['normals.txt', 'images', 'groundtruths', 'masks']\n"
          ]
        }
      ],
      "source": [
        "import os \n",
        "\n",
        "#first put a shortcut in your drive to the image processing folder\n",
        "\n",
        "DATA_DIR = os.path.join('/content',\n",
        "                        'drive',\n",
        "                        'MyDrive',\n",
        "                        'Image Processing and Analysis 2022',\n",
        "                        'projects',\n",
        "                        'Calcification Detection',\n",
        "                        'dataset')\n",
        "\n",
        "\n",
        "print(os.listdir(DATA_DIR))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8nkv1ToTdLO"
      },
      "outputs": [],
      "source": [
        "# os.listdir(DATA_DIR + \"/groundtruths\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jc5Lu21CF2sx"
      },
      "outputs": [],
      "source": [
        "# import opencv\n",
        "import cv2\n",
        "# import numpy\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLGkMjUYVev7"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5RUKbMaE50a"
      },
      "outputs": [],
      "source": [
        "# preprocessing\n",
        "# here explain what you code\n",
        "def preprocessingWavelet(matrix, mask):\n",
        "  # wavelet high pass, low pass or low pass, high pass, high pass high pass.\n",
        "  import pywt  \n",
        "\n",
        "  # enhancement\n",
        "  # Comparing the Performance of Image Enhancement Methods\n",
        "  # to Detect Microcalcification Clusters in Digital Mammography, Moradmand, Hajar, 2012\n",
        "\n",
        "  # Five-level   discrete   wavelet decomposition  was  employed  by  using  Asymmetric Daubechies  of  order  8; \n",
        "\n",
        "  # normal wavelet from stackoverflow\n",
        "  # convert to grayscale\n",
        "  grayscale = cv2.cvtColor(matrix, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  # convert to float\n",
        "  arrayFloat = np.float32(grayscale)\n",
        "  arrayFloat /= 255\n",
        "  \n",
        "  # compute coefficients\n",
        "  coeffs = pywt.wavedec2(arrayFloat,'haar',level=10)\n",
        "\n",
        "  #process coefficients\n",
        "  coeffs_H = list(coeffs)\n",
        "  coeffs_H[0] *= 0\n",
        "\n",
        "  # reconstruction\n",
        "  arrayFloat_H = pywt.waverec2(coeffs_H, 'haar')\n",
        "  arrayFloat_H *= 255\n",
        "  arrayFloat_H = np.uint8(arrayFloat_H)\n",
        "\n",
        "  preprocessed = arrayFloat_H\n",
        "  return preprocessed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cJXfvTTks38"
      },
      "outputs": [],
      "source": [
        "# preprocessing\n",
        "# here explain what you code\n",
        "def preprocessingDeHazingPy(matrix, mask):\n",
        "  # https://link.springer.com/chapter/10.1007/978-3-319-68548-9_27\n",
        "  # the professor say we can take the grays in the mammogram as haze. so use dehazing\n",
        "\n",
        "  # still no the hazing method that he use this is just one found in a python library\n",
        "  # https://github.com/Utkarsh-Deshmukh/Single-Image-Dehazing-Python\n",
        "  # dehazing\n",
        "\n",
        "  import image_dehazer\t# Load the library\n",
        "\n",
        "  hazeCorrectedImg = image_dehazer.remove_haze(matrix)\t\t# Remove Haze\n",
        "\n",
        "  preprocessed = hazeCorrectedImg\n",
        "  return preprocessed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9lVjTTcoC2C"
      },
      "outputs": [],
      "source": [
        "# dehaze single image using dark channel prior and guided filter\n",
        "# taken from a repository \n",
        "# https://github.com/He-Zhang/image_dehaze\n",
        "# dehazing method proposed by the professor \n",
        "# simple imaging dehazing using dark channel prior (and guided filter, readme.md of the repo say that)\n",
        "import math\n",
        "\n",
        "# change this methods to do just grayscale will be nice\n",
        "\n",
        "def DarkChannel(im,sz):\n",
        "    b,g,r = cv2.split(im)\n",
        "    dc = cv2.min(cv2.min(r,g),b);\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(sz,sz))\n",
        "    dark = cv2.erode(dc,kernel)\n",
        "    return dark\n",
        "\n",
        "def AtmLight(im,dark):\n",
        "    [h,w] = im.shape[:2]\n",
        "    imsz = h*w\n",
        "    numpx = int(max(math.floor(imsz/1000),1))\n",
        "    darkvec = dark.reshape(imsz);\n",
        "    imvec = im.reshape(imsz,3);\n",
        "\n",
        "    indices = darkvec.argsort();\n",
        "    indices = indices[imsz-numpx::]\n",
        "\n",
        "    atmsum = np.zeros([1,3])\n",
        "    for ind in range(1,numpx):\n",
        "       atmsum = atmsum + imvec[indices[ind]]\n",
        "\n",
        "    A = atmsum / numpx;\n",
        "    return A\n",
        "\n",
        "def TransmissionEstimate(im,A,sz):\n",
        "    omega = 0.95;# the closer to 1 the stronger the darkenning\n",
        "    im3 = np.empty(im.shape,im.dtype);\n",
        "\n",
        "    for ind in range(0,3):\n",
        "        im3[:,:,ind] = im[:,:,ind]/A[0,ind]\n",
        "\n",
        "    transmission = 1 - omega*DarkChannel(im3,sz);\n",
        "    return transmission\n",
        "\n",
        "def Guidedfilter(im,p,r,eps):\n",
        "    mean_I = cv2.boxFilter(im,cv2.CV_64F,(r,r));\n",
        "    mean_p = cv2.boxFilter(p, cv2.CV_64F,(r,r));\n",
        "    mean_Ip = cv2.boxFilter(im*p,cv2.CV_64F,(r,r));\n",
        "    cov_Ip = mean_Ip - mean_I*mean_p;\n",
        "\n",
        "    mean_II = cv2.boxFilter(im*im,cv2.CV_64F,(r,r));\n",
        "    var_I   = mean_II - mean_I*mean_I;\n",
        "\n",
        "    a = cov_Ip/(var_I + eps);\n",
        "    b = mean_p - a*mean_I;\n",
        "\n",
        "    mean_a = cv2.boxFilter(a,cv2.CV_64F,(r,r));\n",
        "    mean_b = cv2.boxFilter(b,cv2.CV_64F,(r,r));\n",
        "\n",
        "    q = mean_a*im + mean_b;\n",
        "    return q;\n",
        "\n",
        "def TransmissionRefine(im,et):\n",
        "    gray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY);\n",
        "    gray = np.float64(gray)/255;\n",
        "    r = 60;\n",
        "    eps = 0.0001;\n",
        "    t = Guidedfilter(gray,et,r,eps);\n",
        "\n",
        "    return t;\n",
        "\n",
        "def Recover(im,t,A,tx = 0.1):\n",
        "    res = np.empty(im.shape,im.dtype);\n",
        "    t = cv2.max(t,tx);\n",
        "\n",
        "    for ind in range(0,3):\n",
        "        res[:,:,ind] = (im[:,:,ind]-A[0,ind])/t + A[0,ind]\n",
        "    return res\n",
        "\n",
        "def deHazingDarkChannelPriorPy(matrix, mask):\n",
        "\n",
        "    I = matrix.astype(np.float64)/255\n",
        " \n",
        "    dark = DarkChannel(I,15)\n",
        "    A = AtmLight(I,dark)\n",
        "    te = TransmissionEstimate(I,A,15)\n",
        "    t = TransmissionRefine(matrix,te)\n",
        "    J = Recover(I,t,A,0.1)\n",
        "    preprocessed = J\n",
        "    return preprocessed\n",
        "\n",
        "# image = cv2.imread(DATA_DIR+\"/images/53582422_3f0db31711fc9795_MG_R_ML_ANON.tif\")\n",
        "# dark, t, matrix, J = deHazingDarkChannelPriorPy(image, image)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNWyVrjyVvuW"
      },
      "source": [
        "# Candidate Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0KHFD9fFC9y"
      },
      "outputs": [],
      "source": [
        "# candidateExtraction\n",
        "# here explain what you code\n",
        "# Hessian-matrix-based analysis or difference of gaussians (DoH) blob detection from skimage\n",
        "# https://scikit-image.org/docs/stable/api/skimage.feature.html?highlight=local%20binary%20pattern#skimage.feature.blob_doh\n",
        "def candidateExtraction(matrix, mask):\n",
        "\n",
        "  from skimage import feature\n",
        "\n",
        "  # returns x,y,sigma of the blob\n",
        "  blobs = feature.blob_doh(matrix,\n",
        "                           min_sigma=1,\n",
        "                           max_sigma=30,\n",
        "                           num_sigma=10,\n",
        "                           # The absolute lower bound for scale space maxima.\n",
        "                           # Local maxima smaller than threshold are ignored.\n",
        "                           # Reduce this to detect blobs with lower intensities.\n",
        "                           # If threshold_rel is also specified, whichever threshold is larger will be used.\n",
        "                           # If None, threshold_rel is used instead.\n",
        "                           threshold=0.005,\n",
        "                           # lower more sensible, more false positives bad also tinier calcifications detected\n",
        "                           overlap=0.5,\n",
        "                           log_scale=False,\n",
        "                           threshold_rel=None\n",
        "                           )\n",
        "  # taken from the documentation\n",
        "  # ...The downside is that this method can’t be used for detecting blobs of radius less than 3px\n",
        "  # due to the box filters used in the approximation of Hessian Determinant.\n",
        "  result = blobs\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "von-0yGEXbzT"
      },
      "source": [
        "# Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fe7aJb2YhZ9a"
      },
      "outputs": [],
      "source": [
        "# Get Ground Truth for each patch\n",
        "\n",
        "def patchGroundTruth(candidate, groundTruth):\n",
        "\n",
        "  left = int((candidate[0] - candidate[2]) if ((candidate[0] - candidate[2]) > 0) else 0)\n",
        "  right = int((candidate[0] + candidate[2]) if ((candidate[0] + candidate[2]) < groundTruth.shape[0]) else groundTruth.shape[0])\n",
        "  top = int((candidate[1] - candidate[2]) if ((candidate[1] - candidate[2]) > 0) else 0)\n",
        "  bottom = int((candidate[1] + candidate[2]) if ((candidate[1] + candidate[2]) < groundTruth.shape[1]) else groundTruth.shape[1])\n",
        "\n",
        "  truePatch = groundTruth[left : right,\n",
        "                          top  : bottom]\n",
        "  sum = np.sum(truePatch)\n",
        "  if sum > 0:\n",
        "    return str(1)\n",
        "  else:\n",
        "    return str(0)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FavzwRLlRQ31"
      },
      "outputs": [],
      "source": [
        "def patchExtraction(candidate, image):\n",
        "    candidate = candidate.astype(np.int64)\n",
        "\n",
        "    # candidates are y,x and sigma\n",
        "    left = int((candidate[0] - candidate[2]) if ((candidate[0] - candidate[2]) > 0) else 0)\n",
        "    right = int((candidate[0] + candidate[2]) if ((candidate[0] + candidate[2]) < image.shape[0]) else image.shape[0])\n",
        "    top = int((candidate[1] - candidate[2]) if ((candidate[1] - candidate[2]) > 0) else 0)\n",
        "    bottom = int((candidate[1] + candidate[2]) if ((candidate[1] + candidate[2]) < image.shape[1]) else image.shape[1])\n",
        "\n",
        "    patchCandidate = image[left: right,\n",
        "                            top : bottom]\n",
        "    \n",
        "    return patchCandidate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23WbyaI2FhzF"
      },
      "outputs": [],
      "source": [
        "from skimage import feature\n",
        "import itertools\n",
        "\n",
        "# featuresExtraction\n",
        "# here explain what you code\n",
        "def featuresExtraction(matrix, candidates, features, mask, groundTruth, image):\n",
        "  \n",
        "  if (len(candidates) == 0):\n",
        "    return []\n",
        "  # angles\n",
        "  #         0     45      90       135\n",
        "  angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
        "\n",
        "  # https://www.youtube.com/watch?v=5x-CIHRmMNY\n",
        "  # https://scikit-image.org/docs/dev/auto_examples/features_detection/plot_glcm.html\n",
        "  # https://ijcrr.com/uploads/3454_pdf.pdf\n",
        "\n",
        "  flag = True\n",
        "  for index, candidate in enumerate(progress_bar(candidates)):\n",
        "    \n",
        "    # distances\n",
        "    # taking into account the microcalcifications can be less that 5 pixels\n",
        "\n",
        "    #https://www.sciencedirect.com/topics/engineering/cooccurrence-matrix\n",
        "    #distances = [1,3,5,7]\n",
        "    # read more about the variation of distances in glcm computation\n",
        "    distances = [1]# probably we need bigger\n",
        "\n",
        "    # combination of distances and angles as couples of values\n",
        "    distancesAngles = list(itertools.product(distances, angles))\n",
        "\n",
        "    # candidate points are save as np.float64\n",
        "    # to use them as coordinates they have to be integers\n",
        "    patchCandidate, _ = patchExtraction(candidate, matrix)\n",
        "\n",
        "    # reduce even more the shades of gray T-T\n",
        "    # graycomatrix, glcm, receive unsigned integer type\n",
        "    # but if it is bigger that np.uint8 you have to change the levels argument\n",
        "    # of graycomatrix for the shades of gray, if it is np.uint16, levels shoud be\n",
        "    # aprox 65 535. that break the colab :c \n",
        "    patchCandidate = patchCandidate.astype(np.uint8)\n",
        "    dictFeatures = {}\n",
        "    dictFeatures = {'name': 'patch_' + str(index) + '_' + str(image.split(\".\")[0]),\n",
        "                    'label': patchGroundTruth(candidate, groundTruth)}\n",
        "    #print(\"patch_\"+str(index))\n",
        "    #print(patchCandidate)\n",
        "\n",
        "    for distanceAngle in distancesAngles:\n",
        "      distance = distanceAngle[0]\n",
        "      angle = distanceAngle[1]\n",
        "      # get the degree to use it as name for the column\n",
        "      name = str(angle*(180.0/np.pi))\n",
        "      # input image, distance in pixels, angles\n",
        "      #https://stackoverflow.com/questions/54512617/creating-gray-level-co-occurrence-matrix-from-16-bit-image\n",
        "      glcm = feature.graycomatrix(patchCandidate, [ distance ], [ angle ])\n",
        "\n",
        "      # Output: the gray-level co-occurrence histogram. The value P[i,j,d,theta]\n",
        "      # is the number of times that gray-level j occurs at a distance d\n",
        "      # and at an angle theta from gray-level i.\n",
        "      # If normed is False, the output is of type uint32, otherwise it is float64.\n",
        "      # The dimensions are: levels x levels x number of distances x number of angles.\n",
        "\n",
        "      # properties: {‘contrast’, ‘dissimilarity’, ‘homogeneity’, ‘energy’, ‘correlation’, ‘ASM’}\n",
        "      dictFeatures['contrast'+ str(distance) + name] = feature.graycoprops(glcm, 'contrast')[0][0]\n",
        "      dictFeatures['dissimilarity' + str(distance) + name] = feature.graycoprops(glcm, 'dissimilarity')[0][0]\n",
        "      dictFeatures['homogeneity' + str(distance) + name] = feature.graycoprops(glcm, 'homogeneity')[0][0]\n",
        "      dictFeatures['energy' + str(distance) + name] = feature.graycoprops(glcm, 'energy')[0][0]\n",
        "      dictFeatures['correlation' + str(distance) + name] = feature.graycoprops(glcm, 'correlation')[0][0]\n",
        "      dictFeatures['ASM' + str(distance) + name] = feature.graycoprops(glcm, 'ASM')[0][0]\n",
        "\n",
        "      # print(feature.graycoprops(glcm, 'contrast')[0][0])\n",
        "      # print(feature.graycoprops(glcm, 'dissimilarity')[0][0])\n",
        "      # print(feature.graycoprops(glcm, 'homogeneity')[0][0])\n",
        "      # print(feature.graycoprops(glcm, 'energy')[0][0])\n",
        "      # print(feature.graycoprops(glcm, 'correlation')[0][0])\n",
        "      # print(feature.graycoprops(glcm, 'ASM')[0][0])\n",
        "\n",
        "      # https://scikit-image.org/docs/dev/api/skimage.feature.html#skimage.feature.graycoprops\n",
        "      # Compute a feature of a gray level co-occurrence matrix to serve as a compact summary of the matrix.\n",
        "      # The properties are computed as follows:\n",
        "      # contrast\n",
        "      # dissimilarity\n",
        "      # homogeneity\n",
        "      # ASM\n",
        "      # energy\n",
        "      # correlation\n",
        "    # add to the dataframe the features for this patch\n",
        "    features = features.append(dictFeatures, ignore_index=True)\n",
        "    # save in the csv\n",
        "\n",
        "  if(flag):\n",
        "    features.to_csv(os.path.join('/content',\n",
        "                                'drive',\n",
        "                                'MyDrive',\n",
        "                                'Results',\n",
        "                                str(image.split('.')[0]) + '_features.csv'),\n",
        "                    mode='a',\n",
        "                    index=False)\n",
        "    flag = False\n",
        "  else:\n",
        "    features.to_csv(os.path.join('/content',\n",
        "                                'drive',\n",
        "                                'MyDrive',\n",
        "                                'Results',\n",
        "                                str(image.split('.')[0]) + '_features.csv'),\n",
        "                  mode='a',\n",
        "                  header=False,\n",
        "                  index=False)\n",
        "\n",
        "\n",
        "\n",
        "  return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBhB59M3pwiT"
      },
      "outputs": [],
      "source": [
        "# Haar-like features\n",
        "\n",
        "import sys\n",
        "from time import time\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from dask import delayed\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "from skimage.data import lfw_subset\n",
        "from skimage.transform import integral_image\n",
        "from skimage.feature import haar_like_feature\n",
        "from skimage.feature import haar_like_feature_coord\n",
        "from skimage.feature import draw_haar_like_feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjPdr1F5p0fd"
      },
      "outputs": [],
      "source": [
        "@delayed\n",
        "def extract_feature_image(img, feature_type, feature_coord=None):\n",
        "    \"\"\"Extract the haar feature for the current image\"\"\"\n",
        "    ii = integral_image(img)\n",
        "    return haar_like_feature(ii, 0, 0, ii.shape[0], ii.shape[1],\n",
        "                             feature_type=feature_type,\n",
        "                             feature_coord=feature_coord)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_C-AbYe5p29M"
      },
      "outputs": [],
      "source": [
        "def haarLikeFeatureExtraction(image):\n",
        "  # To speed up the example, extract the two types of features only\n",
        "  feature_types = ['type-2-x', 'type-2-y', 'type-3-x', 'type-3-y', 'type-4']\n",
        "\n",
        "\n",
        "  # Extract all possible features\n",
        "  feature_coord, feature_type = \\\n",
        "      haar_like_feature_coord(width=image.shape[1], height=image.shape[0],\n",
        "                              feature_type=feature_types)\n",
        "  return feature_coord, feature_type\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zv5Eq0nqRIl"
      },
      "outputs": [],
      "source": [
        "# Build a computation graph using Dask. This allows the use of multiple\n",
        "# CPU cores later during the actual computation\n",
        "def findHaarFeatures(image, labels):\n",
        "  feature_types = ['type-2-x', 'type-2-y', 'type-3-x', 'type-3-y', 'type-4']\n",
        "  X = delayed(extract_feature_image(image, feature_types))\n",
        "  # Compute the result\n",
        "  X = np.array(X.compute())\n",
        "\n",
        "  return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYRi_ffVWClo"
      },
      "source": [
        "# Connected Components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7G2psxqargQ"
      },
      "outputs": [],
      "source": [
        "# function to get connected components of the ground truth binary image\n",
        "def componentsStatsGroundTruth(matrix):\n",
        "    # getting the info of the components in the ground truth\n",
        "    # second value is connectivity 4 or 8\n",
        "    connectedComponentsGroundTruth = cv2.connectedComponentsWithStats(matrix, 8, cv2.CV_32S)\n",
        "\n",
        "    # Get the results\n",
        "    # The first cell is the number of labels\n",
        "    num_labels = connectedComponentsGroundTruth[0]\n",
        "    # The second cell is the label matrix\n",
        "    labels = connectedComponentsGroundTruth[1]\n",
        "    # The third cell is the stat matrix\n",
        "    stats = connectedComponentsGroundTruth[2]\n",
        "    # The fourth cell is the centroid matrix\n",
        "    centroids = connectedComponentsGroundTruth[3]\n",
        "\n",
        "    return num_labels, labels, stats, centroids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1LCKDC2Wctg"
      },
      "source": [
        "# Get Info from Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAXteeoxLM_z"
      },
      "outputs": [],
      "source": [
        "#import show special for google colab\n",
        "from google.colab.patches import cv2_imshow\n",
        "#import plt for display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#go into de directory of the images\n",
        "\n",
        "# this have 3 outputs root directory, the folders in the path and the files in the path.\n",
        "# we ignore _ the two first because we are not interested in those\n",
        "_, _, images = next(os.walk(os.path.join(DATA_DIR,'images')))\n",
        "_, _, breastMasks = next(os.walk(os.path.join(DATA_DIR,'masks')))\n",
        "_, _, groundTruths = next(os.walk(os.path.join(DATA_DIR, 'groundtruths')))\n",
        "\n",
        "images.sort()\n",
        "breastMasks.sort()\n",
        "groundTruths.sort()\n",
        "\n",
        "# read numbers of normal images\n",
        "normals = []\n",
        "with open(os.path.join(DATA_DIR,'normals.txt')) as f:\n",
        "    for line in f:\n",
        "        normals.append(line[:-1])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quVq5dOEWV-O"
      },
      "source": [
        "# Google Colab like a Pro"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "gGhsM747LRj7",
        "outputId": "f4b3abca-42f9-4abc-9ab7-cbbd791c4065"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "function ClickConnect(){\n",
              "console.log(\"Working\");\n",
              "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
              "}setInterval(ClickConnect,60000)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# https://medium.com/@robertbracco1/configuring-google-colab-like-a-pro-d61c253f7573#a642\n",
        "%%javascript\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\");\n",
        "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "}setInterval(ClickConnect,60000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqItorT9Wr06"
      },
      "source": [
        "# Show Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6mejNA1fgIq"
      },
      "outputs": [],
      "source": [
        "from matplotlib.patches import Circle\n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "# function to draw the grid to display\n",
        "def display_grid(figure, axis, img, imgGroundTruth, preprocessed, candidates, features):\n",
        "  # draw in the axis the img\n",
        "  axis[0][0].imshow(img)\n",
        "  # switch off the axis of the plot\n",
        "  axis[0][0].axis('off')\n",
        "  # set a title for the plot\n",
        "  axis[0][0].set_title('Image')\n",
        "\n",
        "  axis[0][1].imshow(imgGroundTruth, cmap='gray')\n",
        "  axis[0][1].axis('off')\n",
        "  axis[0][1].set_title('Ground Truth')\n",
        "\n",
        "  axis[0][2].imshow(imgMask)\n",
        "  axis[0][2].axis('off')\n",
        "  axis[0][2].set_title('Breast Mask')\n",
        "\n",
        "  axis[1][0].imshow(preprocessed, cmap='gray')\n",
        "  axis[1][0].axis('off')\n",
        "  axis[1][0].set_title('Preprocessed')\n",
        "\n",
        "  # draw candidates as circles\n",
        "  axis[1][1].imshow(preprocessed, cmap='gray')\n",
        "  axis[1][1].axis('off')\n",
        "  axis[1][1].set_title('Candidates')\n",
        "\n",
        "  # Now, loop through coord arrays, and create a circle at each x,y pair\n",
        "  for y,x,sigma in candidates:\n",
        "\n",
        "    blob = Circle((x,y), sigma*5, color='blue', fill=False)\n",
        "    axis[1][1].add_patch(blob)\n",
        "\n",
        "    rect=mpatches.Rectangle((x,y),sigma,sigma, \n",
        "                        fill=False,\n",
        "                        color=\"red\",\n",
        "                       linewidth=2)\n",
        "    axis[1][1].add_patch(rect)\n",
        "\n",
        "\n",
        "  axis[1][2].imshow(imgGroundTruth, cmap='gray')\n",
        "  axis[1][2].axis('off')\n",
        "  axis[1][2].set_title('compare with ground truth and candidates')\n",
        "\n",
        "  # Now, loop through coord arrays, and create a circle at each x,y pair\n",
        "  for y,x,sigma in candidates:\n",
        "    blob = Circle((x,y), sigma, color='blue', fill=False)\n",
        "    axis[1][2].add_patch(blob)\n",
        "  \n",
        "  return figure, axis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91oh7i2wdmJl"
      },
      "outputs": [],
      "source": [
        "def getLargeSigma(candidates):\n",
        "  sigma = [i[2] for i in candidates]\n",
        "  for i in range(len(candidates)):\n",
        "    candidates[i][2] = max(sigma)\n",
        "  return candidates \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8FOBj7KNlRB"
      },
      "outputs": [],
      "source": [
        "def sliding_window(image, stepSize, windowSize, groundTruth):\n",
        "\t# slide a window across the image\n",
        "\tfor y in range(0, image.shape[0], stepSize):\n",
        "\t\tfor x in range(0, image.shape[1], stepSize):\n",
        "\t\t\t# yield the current window\n",
        "\t\t\tyield (x, y, image[y:y + windowSize[1], x:x + windowSize[0]], str(int(np.sum(groundTruth[y:y + windowSize[1], x:x + windowSize[0]])>0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ycDZzgAYDtf"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import clone\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import numpy as np\n",
        "\n",
        "# Boosting algorithm which uses another metric for success.\n",
        "# Algorithm from Wu et al (2008)\n",
        "# Freund (2003)\n",
        "# https://fr.wikipedia.org/wiki/RankBoost\n",
        "\n",
        "# NOTE: I convert y from {0,1} to {-1,+1} and then back again because\n",
        "# it makes it easier for the learning method :P\n",
        "\n",
        "class RankBoost(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, T, base_estimator=None):\n",
        "        if base_estimator is None:\n",
        "            base_estimator = DecisionTreeClassifier(max_depth=1)\n",
        "        self.estimator = base_estimator\n",
        "        self.T = T\n",
        "        self.classes_ = (0, 1)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n0 = np.sum(y == 0)\n",
        "        n1 = np.sum(y == 1)\n",
        "        D = np.repeat(1./(n0*n1), n0*n1)\n",
        "\n",
        "        # emparelhado\n",
        "        #X0 = np.repeat(X[y == 0], n1, 0)\n",
        "        #X1 = np.tile(X[y == 1], (n0, 1))\n",
        "\n",
        "        #Xs = np.r_[X0, X1]\n",
        "        ys = np.r_[np.zeros(n0*n1), np.ones(n0*n1)]\n",
        "\n",
        "        nn = np.sum(y == 1)*np.sum(y == 0)\n",
        "        len_diff = nn*2\n",
        "        Xs = np.zeros((len_diff, X.shape[1]))\n",
        "        #ys = np.zeros(len_diff)\n",
        "\n",
        "        for i, x0 in enumerate(X[y==0]):\n",
        "            for j in range(n1):\n",
        "                Xs[i*n1 + j] = x0\n",
        "\n",
        "        for i, x1 in enumerate(X[y==1]):\n",
        "            for j in range(n0):\n",
        "                Xs[nn + i + n1*j] = x1\n",
        "\n",
        "        \"\"\"\n",
        "        for X1, y1 in zip(X, y):\n",
        "            for X2, y2 in zip(X, y):\n",
        "                if y1 > y2:\n",
        "                    Xs[i] = X2\n",
        "                    #ys[i] = 0\n",
        "                    Xs[i+nn] = X1\n",
        "                    ys[i+nn] = 1\n",
        "                    i += 1\n",
        "        \"\"\"\n",
        "\n",
        "        self.h = [None]*self.T\n",
        "        self.a = [0]*self.T\n",
        "        epsilon = 1e-6  # to avoid division by zero (Schapire and Singer, 1999)\n",
        "\n",
        "        for t in range(self.T):\n",
        "            # Train weak ranker ft based on distribution Dt\n",
        "            Ds = np.r_[D, D]/2\n",
        "            self.h[t] = clone(self.estimator).fit(Xs, ys, Ds)\n",
        "\n",
        "            # Choose alpha\n",
        "            # there are apparently several approaches for this; we are using\n",
        "            # one for a classification base estimator\n",
        "            f_X0 = self.h[t].predict(X[y == 0])\n",
        "            f_X1 = self.h[t].predict(X[y == 1])\n",
        "\n",
        "            \"\"\"\n",
        "            Wneg = 0.\n",
        "            Wpos = 0.\n",
        "            i = 0\n",
        "            for f0 in f_X0:\n",
        "                for f1 in f_X1:\n",
        "                    next_df = f0 - f1\n",
        "                    if next_df == -1:\n",
        "                        Wneg += D[i]\n",
        "                    else:\n",
        "                        Wpos += D[i]\n",
        "                    i += 1\n",
        "            \"\"\"\n",
        "            df = np.repeat(f_X0, n1) - np.tile(f_X1, n0)\n",
        "            \"\"\"\n",
        "            f_X0 = self.h[t].predict(X0)\n",
        "            f_X1 = self.h[t].predict(X1)\n",
        "            df = f_X0 - f_X1  # (n0*n1)\n",
        "            \"\"\"\n",
        "\n",
        "            Wneg = np.sum(D[df == -1])  # right\n",
        "            Wpos = np.sum(D[df == +1])  # wrong\n",
        "\n",
        "            self.a[t] = 0.5*np.log((Wneg+epsilon)/(Wpos+epsilon))\n",
        "\n",
        "            # Update D\n",
        "            D = D*np.exp(self.a[t]*df)\n",
        "            D = D/np.sum(D)  # normalize distribution\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.sum([a*h.predict(X) for a, h in zip(self.a, self.h)], 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GHlP95OW6e6"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvN0mEoZI53S",
        "outputId": "2473616a-611e-4ccb-bae8-e6431ef09cb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4084, 3328, 3)\n"
          ]
        }
      ],
      "source": [
        "for image in images:\n",
        "  img = cv2.imread(os.path.join(DATA_DIR,'images',image))\n",
        "  print(img.shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "qqqX2PGi6-X8",
        "outputId": "05af32fc-5d3c-4ab5-937e-241f31bed4c1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='1' class='' max='410' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.24% [1/410 50:02<341:06:07]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image:  20586908_6c613a14b80a8591_MG_R_CC_ANON.tif\n",
            "13312\n",
            "image:  20586934_6c613a14b80a8591_MG_L_CC_ANON.tif\n"
          ]
        }
      ],
      "source": [
        "import copy\n",
        "import pandas as pd\n",
        "\n",
        "#go through the image files \n",
        "X = []\n",
        "labels = []\n",
        "flag = True\n",
        "\n",
        "for image, breastMask, groundTruth in zip(progress_bar(images), breastMasks, groundTruths):\n",
        "  # choose one\n",
        "  # this are the last 4 of the number of the image name {numbers}_{}_{}_{}_{}_{}.tif\n",
        "  # i suppose those are unique\n",
        "  # if your code is working try other images!\n",
        "  #print(breastMask)\n",
        "  \n",
        "  # restart variables for memory\n",
        "\n",
        "  # to save the features generated with the glcm\n",
        "  features = pd.DataFrame(dtype=np.float64)\n",
        "  # to save the candidates\n",
        "  blobs = {}\n",
        "  # to sabe the ground truth connected components\n",
        "  groundTruthsComponents = {}\n",
        "\n",
        "  try:\n",
        "    done_list = pd.read_csv(os.path.join('/content',\n",
        "                                      'drive',\n",
        "                                      'MyDrive',\n",
        "                                      'Results',\n",
        "                                      'X_train2.csv'))['name'].values.tolist()\n",
        "    done_list = [i.split('_')[0] for i in done_list]\n",
        "    flag = False\n",
        "  \n",
        "  except:\n",
        "    done_list = []\n",
        "  \n",
        "\n",
        "  # 20588020, 7717, 5328, 3787, 5725, 3859, 6934, 50995872\n",
        "  digits = '5328'\n",
        "\n",
        "  #if ((digits in image) and (digits in breastMask) and ('mask' in breastMask)):\n",
        "  if ('mask' in breastMask):\n",
        "  #if image not in already:\n",
        "    print(\"image: \", image)\n",
        "    #upload images\n",
        "    img = cv2.imread(os.path.join(DATA_DIR,'images',image))\n",
        "    imgMask = cv2.imread(os.path.join(DATA_DIR, 'masks', breastMask))\n",
        "    imgGroundTruth = cv2.imread(os.path.join(DATA_DIR, 'groundtruths', image), cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "\n",
        "    # processing necessary for evaluation\n",
        "\n",
        "    # Get components of the ground truth\n",
        "    '''\n",
        "    num_labels, labels, stats, centroids = componentsStatsGroundTruth(imgGroundTruth)\n",
        "    groundTruthsComponents[image] = {}\n",
        "    groundTruthsComponents[image]['num_labels'] = num_labels\n",
        "    groundTruthsComponents[image]['labels'] = labels\n",
        "    groundTruthsComponents[image]['stats'] = stats\n",
        "    groundTruthsComponents[image]['centroids'] = centroids\n",
        "    '''\n",
        "    # preprocessing #\n",
        "\n",
        "    imgCopy = copy.deepcopy(img)\n",
        "\n",
        "    # preprocessed = preprocessingDeHazingPy(img, imgMask)\n",
        "    preprocessed = deHazingDarkChannelPriorPy(imgCopy, imgMask)\n",
        "    # after preprocessingDeHazingPy + contrast streching to see\n",
        "    # preprocessed = preprocessingDeHazingPy(imgCopy,imgMask)\n",
        "\n",
        "      # still missing quantum noise supression\n",
        "      # details in the phd defense file\n",
        "\n",
        "      # still missing linear streching\n",
        "        # keep going forever the code, computational cost\n",
        "\n",
        "      # still missing CLAHE (adaptive histogram equalization) opencv library\n",
        "        # CLAHE + dehazing bad results.\n",
        "        # points less visible with CLAHE\n",
        "\n",
        "        # dehazing + CLAHE \n",
        "        # black image\n",
        "\n",
        "      # Observations from the results:\n",
        "\n",
        "        # fiber intersections may also appear as bright spots (false positives)\n",
        "\n",
        "      # THINGS WE NOTICE BETWEEN BOTH DEHAZING METHODS\n",
        "\n",
        "        # Better suppression of fatty tissue (noise) and greater enhancement of brightness of desired feature (microcalcifications)\n",
        "\n",
        "        # sometimes for the other dehazing method black patches become present in the fatty tissue\n",
        "        # this did not happen in the dehazing with dark channel prior (and guided filter)\n",
        "\n",
        "        # sharper\n",
        "\n",
        "        # enhance the contrast\n",
        "\n",
        "        # details were enhanced\n",
        "\n",
        "    # candidate extraction #\n",
        "\n",
        "    copyPreprocessed = copy.deepcopy(preprocessed)\n",
        "\n",
        "    # we have to change np.float64 to np.float32 for the grayscale conversion\n",
        "    # leading to a reduction of gray values\n",
        "    copyPreprocessed = copyPreprocessed.astype(np.float32)\n",
        "    copyPreprocessed = cv2.cvtColor(copyPreprocessed, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "#    candidates = candidateExtraction(copyPreprocessed, imgMask)\n",
        "    winW=15\n",
        "    winH=15\n",
        "    counter = 0\n",
        "\n",
        "    for (x, y, window, label) in sliding_window(copyPreprocessed, stepSize=32, windowSize=(winW, winH), groundTruth=imgGroundTruth):\n",
        "      df = pd.DataFrame()\n",
        "      # if the window does not meet our desired window size, ignore it\n",
        "      if window.shape[0] != winH or window.shape[1] != winW:\n",
        "        continue\n",
        "      \n",
        "      feature_coord, feature_type = haarLikeFeatureExtraction(window)\n",
        "\n",
        "      X_ini = findHaarFeatures(window, label)\n",
        "      window_name = image.split('_')[0] + '_'+ str(counter)\n",
        "\n",
        "      df['HaarFeatures'] = [X_ini]\n",
        "      df['label'] = label\n",
        "      df['name'] = window_name\n",
        "\n",
        "      if(flag):\n",
        "        df.to_csv(os.path.join('/content',\n",
        "                                    'drive',\n",
        "                                    'MyDrive',\n",
        "                                    'Results',\n",
        "                                    'X_train2.csv'),\n",
        "                        mode='a',\n",
        "                        index=False)\n",
        "        flag = False\n",
        "      else:\n",
        "        df.to_csv(os.path.join('/content',\n",
        "                                    'drive',\n",
        "                                    'MyDrive',\n",
        "                                    'Results',\n",
        "                                    'X_train2.csv'),\n",
        "                      mode='a',\n",
        "                      header=False,\n",
        "                      index=False)\n",
        "      \n",
        "      counter += 1\n",
        "    print(counter)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Observations from the results:\n",
        "\n",
        "\n",
        "      # images with pectoral muscule cause false positives\n",
        "\n",
        "    # feature extraction #\n",
        "\n",
        "    # features = featuresExtraction(copyPreprocessed, candidates, features, imgMask, imgGroundTruth, image)\n",
        "\n",
        "    \n",
        "    # machine learning must be applied for the classification of the features extracted\n",
        "\n",
        "    import gc\n",
        "\n",
        "    del features\n",
        "    del preprocessed\n",
        "    del X_ini\n",
        "#    del candidates\n",
        "    del blobs\n",
        "    del copyPreprocessed\n",
        "    del imgCopy\n",
        "    del img\n",
        "    del imgMask\n",
        "    del imgGroundTruth\n",
        "    \n",
        "    gc.collect()\n",
        "    \n",
        "    # end image processing part #\n",
        "\n",
        "    # processing necessary for evaluation #\n",
        "\n",
        "    # save blobs results to check groundtruth\n",
        "    #blobs[image] = candidates\n",
        "\n",
        "\n",
        "    # display related #\n",
        "\n",
        "    # matrix of plots and size of the figure\n",
        "    # figure, axis = plt.subplots(2, 3, figsize=(15,15))\n",
        "\n",
        "    # display_grid(figure, axis, img, imgGroundTruth, preprocessed, candidates, features)\n",
        " \n",
        "    # plt.subplots_adjust(wspace=0, hspace=0)\n",
        "\n",
        "    # # display figure with image\n",
        "    # plt.show()\n",
        "\n",
        "    # # extract patches of candidates\n",
        "    # for index, candidate in enumerate(candidates):\n",
        "    #   print(\"candidate: \", index)\n",
        "    #   left = int((candidate[0] - candidate[2]) if ((candidate[0] - candidate[2]) > 0) else 0)\n",
        "    #   right = int((candidate[0] + candidate[2]) if ((candidate[0] + candidate[2]) < preprocessed.shape[0]) else preprocessed.shape[0])\n",
        "    #   top = int((candidate[1] - candidate[2]) if ((candidate[1] - candidate[2]) > 0) else 0)\n",
        "    #   bottom = int((candidate[1] + candidate[2]) if ((candidate[1] + candidate[2]) < preprocessed.shape[1]) else preprocessed.shape[1])\n",
        "\n",
        "    #   plt.imshow(preprocessed[left:right, top:bottom])\n",
        "    #   plt.show()\n",
        "\n",
        "    # display image with other function\n",
        "    #cv2_imshow(features)\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "id": "J-h5mAD_aEe0",
        "outputId": "788b8442-927f-4d6f-9c56-6a7d5c94b375"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-bb95eb4c-37b2-41ea-91ec-286667449c7e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>HaarFeatures</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb95eb4c-37b2-41ea-91ec-286667449c7e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bb95eb4c-37b2-41ea-91ec-286667449c7e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bb95eb4c-37b2-41ea-91ec-286667449c7e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [name, HaarFeatures, label]\n",
              "Index: []"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ovsk8poLc_jz",
        "outputId": "c4370871-7d7d-495a-d780-d7a4a4822e42"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0.04132903, -0.0805403 , -0.12186933,  0.08377564,  0.00435293,\n",
              "       -0.07942271,  0.16319835])"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=150,\n",
        "                                                    random_state=0,\n",
        "                                                    stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjT7XldaA5zP",
        "outputId": "4e474a13-6544-415b-fc02-9e160b9f85f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "403\n"
          ]
        }
      ],
      "source": [
        "files = os.listdir(\"/content/drive/MyDrive/Results\")\n",
        "print(len(files))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "-YxtDuR3reuX",
        "outputId": "f6f209ee-b251-4a93-f312-bb38e9a2f95e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='410' class='' max='410' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [410/410 00:00<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import copy\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(columns=['names'])\n",
        "\n",
        "#go through the image files \n",
        "for image, breastMask, groundTruth in zip(progress_bar(images), breastMasks, groundTruths):\n",
        "\n",
        "  #if ((digits in image) and (digits in breastMask) and ('mask' in breastMask)):\n",
        "  if ('mask' in breastMask):\n",
        "    \n",
        "    df = df.append({'names': image}, ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "OQYG-9Qg4yvg",
        "outputId": "5bec2741-f093-4295-b6ee-ccb3ad11a9fa"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-bae9a2f20e94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                         \u001b[0;34m'MyDrive'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                         \u001b[0;34m'Results'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                         'names.csv'))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Results/names.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "features = pd.read_csv(os.path.join('/content',\n",
        "                        'drive',\n",
        "                        'MyDrive',\n",
        "                        'Results',\n",
        "                        'names.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVP2PHW9E66x"
      },
      "outputs": [],
      "source": [
        "\n",
        "df.to_csv( os.path.join('/content',\n",
        "                        'drive',\n",
        "                        'MyDrive',\n",
        "                        'Results',\n",
        "                        'names.csv'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Gag035mepoZ"
      },
      "outputs": [],
      "source": [
        "# save images\n",
        "'''\n",
        "cv2.imwrite(os.path.join('/content',\n",
        "                        'drive',\n",
        "                        'MyDrive',\n",
        "                        'Results',\n",
        "                         'features.csv'),\n",
        "            features)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJrrb3dxTR6P"
      },
      "outputs": [],
      "source": [
        "# evaluation froc curve #\n",
        "\n",
        "''''\n",
        "fp = 0 # false positive, findings on normal images, don't forget the normals variable\n",
        "tp = 0 # true positive, for the blobs that are inside a component\n",
        "fn = 0 # false negative, for the blobs that do not belong to any component\n",
        "\n",
        "for key in groundTruthsComponents:\n",
        "  # list of features found with y,x and sigma\n",
        "  featuresImg = blobs[key]\n",
        "  \n",
        "  # restart the variables\n",
        "  fp = 0\n",
        "  tp = 0\n",
        "  fn = 0\n",
        "\n",
        "  # is the image a normal image?\n",
        "  if (key in normals):\n",
        "    # if it is false positive\n",
        "    fp = fp + 1\n",
        "    continue\n",
        "\n",
        "  # if it is not register as normal\n",
        "  # stat have 5 items: leftmost x coordinate,\n",
        "  #                    topmost y coordinate,\n",
        "  #                    horizontal size of the bounding box\n",
        "  #                    vertical size of the bounding box\n",
        "  #                    total area in pixels of the connected component\n",
        "  for centroid, stat in zip(groundTruthsComponents[key]['centroids'], groundTruthsComponents[key]['stats']):\n",
        "    # remember one component is the background\n",
        "    \n",
        "    if (stat[0] == 0):\n",
        "      # is the background\n",
        "      continue\n",
        "\n",
        "    # top left is the 0,0 of the image\n",
        "    \n",
        "    topX = stat[0]\n",
        "    bottomX = stat[0] + stat[2]\n",
        "\n",
        "    topY = stat[1]\n",
        "    bottomY = stat[1] + stat[3]\n",
        "\n",
        "    matchs = [1 for feature in featuresImg if (( feature[1] >= topX ) and\n",
        "                                               ( feature[1] <= bottomX ) and\n",
        "                                               ( feature[0] >= topY ) and\n",
        "                                               ( feature[0] <= bottomY )) ]\n",
        "\n",
        "    # true positives\n",
        "    tp = tp + np.sum(matchs)\n",
        "\n",
        "\n",
        "    #false negatives will be the difference between the total true positives and the blobs that we receive\n",
        "\n",
        "  fn = len(featuresImg) - tp\n",
        "\n",
        "  # save and compute tpr and fpr\n",
        "\n",
        "  # to make te roc curve i need scores... clasification :|\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uo57LPvjVEEf"
      },
      "outputs": [],
      "source": [
        "\n",
        "features.to_csv( os.path.join('/content',\n",
        "                        'drive',\n",
        "                        'MyDrive',\n",
        "                        'Results',\n",
        "                        'features.csv'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6B64-S9blVud"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CalcificationTestImageProcessing.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}