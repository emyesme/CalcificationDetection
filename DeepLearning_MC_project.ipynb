{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearning_MC_project.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP45dhzQi8ThcOTlXr0xKPZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emyesme/CalcificationDetection/blob/feature-pm/DeepLearning_MC_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAem5pBbW9eM",
        "outputId": "1e8b2924-0af3-4068-8f3a-53789ee158c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "\n",
        "#first put a shortcut in your drive to the image processing folder\n",
        "\n",
        "RESULTS_DIR = os.path.join('/content',\n",
        "                        'drive',\n",
        "                        'MyDrive',\n",
        "                        'Results')\n",
        "\n",
        "\n",
        "DATA_DIR = os.path.join('/content',\n",
        "                        'drive',\n",
        "                        'MyDrive',\n",
        "                        'Image Processing and Analysis 2022',\n",
        "                        'projects',\n",
        "                        'Calcification Detection',\n",
        "                        'dataset')\n",
        "\n",
        "\n",
        "print(os.listdir(RESULTS_DIR))\n",
        "\n",
        "data_file = os.listdir(RESULTS_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u27ZtWK1XAY-",
        "outputId": "09172072-519b-459d-a7e6-91845ca7d28b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['X_train.csv', 'test', 'X_train2.csv', 'X_train3.csv', '4.dehazingDC+DoH(0.0005)+GLCM', '5.dehazingDilBlur+DoH+GLCM', 'FROC_calculations_KNN_pip4_5296.csv', 'FROC_calculations_DT_pip4_fn5173_normals57.csv', 'FROC_calculations_DT_pip4_fn294_normals57.csv', 'FROC_calculations_DT_pip6_fn235_normals39.csv', 'FROC_calculations_DT_pip6_fn257_normals37.csv', 'FROC_calculations_DT_pip6_fn203_normals57.csv', 'FROC_calculations_DT_pip4_fn203_normals57.csv', '8.dehazingDil+DoG+GLCM', '6.dehazingMorph+DoH+HaarWaveletGLCM', '10.CLAHE+Dehazing+Dil(3,3)+DoGTweak+GLCM', 'groundTruthStats.gsheet', 'groundTruthStats.csv', 'DehazingDarkChannel_GuidedFilter', 'CLAHE+Dehazing', 'CLAHE+Dehazing+GrayMorph', '10-1.CLAHE+Dehazing+Dil(3,3)+DoGTweak(0.06)+GLCM', 'Pipeline_Prepro10-DoGTweakOf8', 'TestLBP', '13.CLAHE+Dehazing+Dil(3,3)+DoG(10)+LBP+GLCM', '12.CLAHE+Dehazing+GrayMorph+Dil(3,3)+DoGTweak', 'Patches_complete', 'Patches', '10', '12', 'FROC_calculations_SVM-SEL_pip10_fn479_normals57.csv', 'FROC_calculations_SVM-SEL_pip10_fn479_normals57_fp.csv', 'SensitivityResults', 'Calcification Detection.gslides', 'CandidatesPipeline8', 'CandidatesPipeline10', 'FROC_calculations_SVM-SEL_pip10_fn167_normals57.csv', 'clahe+dehazing+bgr (1)', 'clahe+dehazing+bgr', 'clahe+dehazing+bgr1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9rhux8SW0Ts"
      },
      "outputs": [],
      "source": [
        "# import the required packages\n",
        "import os\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.data as data\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "batch_size = 32\n",
        "learning_rate = 0.02\n",
        "epochs = 30\n",
        "momentum = 0.1\n",
        "lr_step_size = 1000   # if < epochs, we are using decaying learning rate\n",
        "lr_gamma = 0.1\n",
        "data_augmentation = True\n",
        "dropout = 0.1\n",
        "activation = nn.LeakyReLU()\n",
        "\n",
        "# make visible only one GPU at the time\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # <-- should be the ID of the GPU you want to use\n",
        "\n",
        "# options\n",
        "# device = \"cuda:0\"           # put here \"cuda:0\" if you want to run on GPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "monitor_display = True      # whether to display monitored performance plots\n",
        "display_first_n = 0         # how many samples/batches are displayed\n",
        "num_workers = 2             # how many workers (=threads) for fetching data\n",
        "pretrained = False          # whether to test a pretrained model (to be loaded) or train a new one\n",
        "display_errors = True       # whether to display errors (only in pretrained mode)"
      ],
      "metadata": {
        "id": "I0CzC_YGW1Yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4ZxH2BvIYZae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vtidrNeyYehC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load information**"
      ],
      "metadata": {
        "id": "gm8zZBDDYdjy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import roi_cc_project\n",
        "\n",
        "dataset = roi_cc_project.UnlabeledImageROI(os.path.join(DATA_DIR, 'images', '20586908_6c613a14b80a8591_MG_R_CC_ANON.tif'),os.path.join(DATA_DIR, 'groundtruths', '20586908_6c613a14b80a8591_MG_R_CC_ANON.tif'), (12,12), img_channel=None, preprocessing=None, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSDpWbCcXc9o",
        "outputId": "973326eb-bbd0-4185-f07e-c854c691835f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...5129587 ROIs extracted in 66 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Convert(object):\n",
        "    def __call__(self, img):\n",
        "      return torch.from_numpy(np.transpose(img.astype(np.float32), (2, 0, 1))).float()\n",
        "        # return torch.unsqueeze(torch.from_numpy(np.array(img)), 0).float()\n",
        "\n",
        "# define Flatten transform so as to have a 28x28=784 tensor\n",
        "class Flatten(object):\n",
        "    def __call__(self, img):\n",
        "        return img.view(12*12)\n",
        "\n",
        "# define target transform so as to have a 1-hot tensor\n",
        "class OneHot(object):\n",
        "    def __call__(self, label):\n",
        "        #target = torch.zeros(10, dtype=torch.float)\n",
        "        #target[label] = 1.0\n",
        "        return label\n",
        "\n",
        "\n",
        "transform_train = transforms.Compose(\n",
        "     [Convert(),\n",
        "      # transforms.ToTensor(),\n",
        "     Flatten()])\n",
        "# transform_test = transforms.Compose(\n",
        "#     [Convert(),\n",
        "# #     transforms.Normalize(mean=[mu], std=[std]),\n",
        "#      Flatten()])\n",
        "\n"
      ],
      "metadata": {
        "id": "lJ4ZsdP4ZVj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check your original data, before applying any transform\n",
        "# NOTE: we also calculate data mean and standard deviation\n",
        "print (\"\\nTrain data are %d, with shape %s\" % (len(train_features), train_features.shape))\n",
        "mu = train_features.float().mean()\n",
        "std = train_features.float().std()\n",
        "print (\"...with mean %.1f and standard deviation %.1f\" % (mu, std))\n",
        "print (\"...with labels %s, %s, %s, ...\" % (np.unique(train_labels)[0], np.unique(train_labels)[1]))\n",
        "# mu_valid = dataset_valid.data.float().mean()\n",
        "# std_valid = dataset_valid.data.float().std()\n",
        "# print (\"\\nValidation data are %d, with shape %s\" % (len(dataset_valid), dataset_valid.data.shape))\n",
        "# print (\"...with mean %.1f and standard deviation %.1f\" % (mu_valid, std_valid))\n",
        "# print (\"...with labels %s, %s, %s, ...\" % (dataset_valid.targets[0], dataset_valid.targets[1], dataset_valid.targets[2]))\n",
        "# # visual check\n",
        "# for i in range(0, display_first_n):\n",
        "#     plt.imshow(dataset_train.data[i], cmap='gray')\n",
        "#     plt.title('Training Sample %d' % i)\n",
        "#     plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "qHt3_FWoJHa0",
        "outputId": "a2ad46a8-f5b3-4223-cb46-0568de4871e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-3a37f1db146b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# check your original data, before applying any transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# NOTE: we also calculate data mean and standard deviation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nTrain data are %d, with shape %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_features' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sa7uu6o7YozU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train test split"
      ],
      "metadata": {
        "id": "54ORzJinY3Fy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1s5zPAAdxBro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_percentage = 0.6\n",
        "test_percentage = 0.25\n",
        "\n",
        "train_size = int(len(dataset)*train_percentage)\n",
        "test_size = int(len(dataset)*test_percentage)\n",
        "\n",
        "indices = list(range(len(dataset)))\n",
        "np.random.shuffle(indices)\n",
        "train_indices, test_indices, val_indices = indices[:train_size], indices[train_size:train_size+test_size], indices[train_size+test_size:]\n",
        "train_features = data.SubsetRandomSampler(train_indices)\n",
        "val_features = data.SubsetRandomSampler(val_indices)\n",
        "test_features = data.SubsetRandomSampler(test_indices)"
      ],
      "metadata": {
        "id": "Bd864xCEiZng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader_train = torch.utils.data.DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, pin_memory=True, sampler=train_features)\n",
        "dataloader_val = torch.utils.data.DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, pin_memory=True, sampler=val_features)\n",
        "dataloader_test = torch.utils.data.DataLoader(dataset, batch_size=batch_size, num_workers=num_workers, pin_memory=True, sampler=test_features)\n",
        "\n",
        "dataloader = {'train': dataloader_train, 'eval': dataloader_val, 'test': dataloader_test}\n",
        "dataset_sizes = {'train': train_size, 'eval': len(dataset)-train_size-test_size,'test': test_size}"
      ],
      "metadata": {
        "id": "GM_jp5acK70y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model definition"
      ],
      "metadata": {
        "id": "9DDuCOfTYaKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define CNN\n",
        "\n",
        "###\n",
        "# Haq, I.U., Ali, H., Yu, W.H., Lei, C., Ali, H., Feature fusion and ensemble learning\u0002based CNN model for mammographic image classification, Journal of King Saud University - Computer and\n",
        "# Information Sciences (2022), doi: https://doi.org/10.1016/j.jksuci.2022.03.023\n",
        "###\n",
        "\n",
        "## leakyrelu used instead of elu\n",
        "## Adam optimizer with a learning rate of 0.0001, β1 of 0.9, and β2 of 0.99, and a batch size of 24\n",
        "\n",
        "class CD_CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CD_CNN, self).__init__()\n",
        "        \n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1) #kernel_size=7\n",
        "        # kernel sizes reduced due to patch size\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1) #kernel_size=7\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) # stride? padding?\n",
        "        #https://stackoverflow.com/questions/63971920/why-am-i-getting-calculated-padding-input-size-per-channel-smaller-than-kernel-s\n",
        "        self.dropout1=nn.Dropout(p=0.2)\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "\n",
        "        #self.dwconv1 = nn.DepthwiseConv2D(in_channels=64, out_channels=128, kernel_size=5, padding=1)\n",
        "        self.dwconv1 = nn.Conv2d(in_channels=64, out_channels=128, groups= 64, kernel_size=3, padding=1) #kernel_size=5\n",
        "        #https://discuss.pytorch.org/t/attributeerror-module-torch-nn-has-no-attribute-conv2d/90038\n",
        "        #https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html        \n",
        "        self.bn4 = nn.BatchNorm2d(128)\n",
        "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1) #kernel_size=5\n",
        "        self.bn5 = nn.BatchNorm2d(128)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.dropout2=nn.Dropout(p=0.2)\n",
        "        self.bn6 = nn.BatchNorm2d(128)\n",
        "\n",
        "        #self.dwconv2 = nn.DepthwiseConv2D(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
        "       \n",
        "        # third block removed due to patch size\n",
        "        # self.dwconv2 = nn.Conv2d(in_channels=128, out_channels=256, groups= 128, kernel_size=3, padding=1)\n",
        "        # self.bn7 = nn.BatchNorm2d(256)\n",
        "        # self.conv4 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
        "        # self.bn8 = nn.BatchNorm2d(256)\n",
        "        # self.conv5 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)\n",
        "        # self.bn9 = nn.BatchNorm2d(256)\n",
        "        # self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        # self.dropout3=nn.Dropout(p=0.2)\n",
        "        # self.bn10 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.fc1 = nn.Linear(128*3*3,512) #128*3*3 is output size of previous stage\n",
        "        self.fc2 = nn.Linear(512,2) # 2?\n",
        "\n",
        "        self.out = nn.Sigmoid()\n",
        "\n",
        "        \n",
        "        \n",
        "        self.act = activation\n",
        "\n",
        "        #self.act = nn.Sigmoid()\n",
        "\n",
        "        nn.init.xavier_normal_(self.conv1.weight)\n",
        "        nn.init.xavier_normal_(self.conv2.weight)\n",
        "        nn.init.xavier_normal_(self.conv3.weight)\n",
        "       # nn.init.xavier_normal_(self.conv4.weight)\n",
        "       # nn.init.xavier_normal_(self.conv5.weight)\n",
        "        nn.init.xavier_normal_(self.dwconv1.weight)\n",
        "       # nn.init.xavier_normal_(self.dwconv2.weight)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.act(self.bn1(self.conv1(x)))\n",
        "        x = self.act(self.bn2(self.conv2(x)))\n",
        "        x = self.pool1(x)\n",
        "        x = self.bn3(self.dropout1(x))\n",
        "        # print(x.size())\n",
        "\n",
        "        x = self.act(self.bn4(self.dwconv1(x)))\n",
        "        x = self.act(self.bn5(self.conv3(x)))\n",
        "        x = self.pool2(x)\n",
        "        x = self.bn6(self.dropout2(x))\n",
        "        # print(x.size())\n",
        "\n",
        "        # x = self.act(self.bn7(self.dwconv2(x)))\n",
        "        # x = self.act(self.bn8(self.conv4(x))) \n",
        "        # x = self.act(self.bn9(self.conv5(x))) \n",
        "        # x = self.pool3(x)\n",
        "        # x = self.bn10(self.dropout3(x))\n",
        "        # print(x.size())\n",
        "\n",
        "        x = x.view(-1, 128*3*3)\n",
        "        x = self.act(self.fc1(x))\n",
        "\n",
        "        # print(x.size())\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        # no activation: \"remember in this case to not specify the activation in the last layer when you define the net!\"\n",
        "        # consider softmax/logsoftmax\n",
        "        \n",
        "        # print(x.size())\n",
        "        \n",
        "        x = self.out(x)\n",
        "\n",
        "        # print(x.size())\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "4KHpATwIW29l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DeepNet(nn.Module):\n",
        "    def __init__(self):\n",
        "       super(DeepNet, self).__init__()\n",
        "       self.fc1 = nn.Linear(144, 100)\n",
        "       self.fc2 = nn.Linear(100, 100)\n",
        "       self.fc3 = nn.Linear(100, 10)\n",
        "\n",
        "       nn.init.xavier_normal_(self.fc1.weight)\n",
        "       nn.init.xavier_normal_(self.fc2.weight)\n",
        "       nn.init.xavier_normal_(self.fc3.weight)\n",
        "\n",
        "       self.bn1 = nn.BatchNorm1d(100)\n",
        "       self.bn2 = nn.BatchNorm1d(100)\n",
        "\n",
        "       self.act = activation\n",
        "\n",
        "       self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.act(self.bn1(self.fc1(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.act(self.bn2(self.fc2(x)))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "dm0MhGYYI1TU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN1(nn.Module):\n",
        "  def __init__(self) -> None:\n",
        "      super(CNN1, self).__init__()\n",
        "\n",
        "      # in_channels is number of channels (this is because we have a patch of 1 image)\n",
        "      # out_channels is number of filters or kernels given out by the convolution\n",
        "      # stride is a parameter (default is 1)\n",
        "      self.conv1 =  nn.Conv2d(in_channels=1, out_channels=64, kernel_size=2, padding=1)\n",
        "      self.bn1 = nn.BatchNorm2d(64)\n",
        "      self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=2, padding=1)\n",
        "      self.bn2 = nn.BatchNorm2d(64)\n",
        "      self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
        "      self.dropout1=nn.Dropout(p=0.2)\n",
        "      self.bn3 = nn.BatchNorm2d(64)\n",
        "\n",
        "      self.flatten = nn.Flatten()\n",
        "\n",
        "      self.fc1 = nn.Linear(3136,512)\n",
        "      self.fc2 = nn.Linear(512,2)\n",
        "\n",
        "      nn.init.xavier_normal_(self.fc1.weight)\n",
        "      nn.init.xavier_normal_(self.fc2.weight)\n",
        "      nn.init.xavier_normal_(self.conv1.weight)\n",
        "      nn.init.xavier_normal_(self.conv2.weight)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "      x = self.conv1(x)\n",
        "      x = self.bn1(x)\n",
        "      x = self.conv2(x)\n",
        "      x = self.conv2(x)\n",
        "      x = self.pool1(x)\n",
        "      x = self.dropout1(x)\n",
        "      x = self.bn3(x)\n",
        "      x = self.flatten(x)\n",
        "      x = self.fc1(x)\n",
        "      x = activation(x)\n",
        "      x = self.fc2(x)\n",
        "\n",
        "      return x\n",
        "\n"
      ],
      "metadata": {
        "id": "NA8pQj2raNKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "net = CNN1()\n",
        "summary(net, (1,12,12))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ti68kRkObivY",
        "outputId": "4ff6048c-7b69-4348-ad15-03420973b5ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 13, 13]             320\n",
            "       BatchNorm2d-2           [-1, 64, 13, 13]             128\n",
            "            Conv2d-3           [-1, 64, 14, 14]          16,448\n",
            "            Conv2d-4           [-1, 64, 15, 15]          16,448\n",
            "         MaxPool2d-5             [-1, 64, 7, 7]               0\n",
            "           Dropout-6             [-1, 64, 7, 7]               0\n",
            "       BatchNorm2d-7             [-1, 64, 7, 7]             128\n",
            "           Flatten-8                 [-1, 3136]               0\n",
            "================================================================\n",
            "Total params: 33,472\n",
            "Trainable params: 33,472\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.47\n",
            "Params size (MB): 0.13\n",
            "Estimated Total Size (MB): 0.59\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_variable = torch.rand(1,1,12,12) #batch size, channel, image size\n",
        "net(dummy_variable).size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaR5MArqg8e5",
        "outputId": "9d6764b5-e59a-4c13-a324-7a119a7daa8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3136])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net = CNN1().to(device) #we need to also send the model to the GPU as well\n",
        "\n",
        "# create loss function\n",
        "criterion = nn.CrossEntropyLoss() #most used for classification purposes\n",
        "\n",
        "# create SGD optimizer\n",
        "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum) #most common optimizer is adam\n",
        "\n",
        "# create learning rate scheduler\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=lr_step_size, gamma=lr_gamma)\n",
        "\n",
        "# experiment ID\n",
        "experiment_ID = \"%s_%s_%s_bs(%d)lr(%.4f_%d_%.1f)m(%.1f)e(%d)act(%s)xavier(yes)da(%s)do(%.1f)BN\" % (type(net).__name__, type(criterion).__name__, type(optimizer).__name__,\n",
        "                batch_size, learning_rate, lr_step_size, lr_gamma, momentum, epochs, type(activation).__name__, data_augmentation, dropout)"
      ],
      "metadata": {
        "id": "Emo3pdAQIPe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define train function (1 epoch)\n",
        "# returns average loss and accuracy\n",
        "def train(dataset, dataloader):\n",
        "\n",
        "    # switch to train mode\n",
        "    net.train()\n",
        "\n",
        "    # reset performance measures\n",
        "    loss_sum = 0.0\n",
        "    correct = 0\n",
        "\n",
        "    # 1 epoch = 1 complete loop over the dataset\n",
        "    for batch in dataloader:\n",
        "\n",
        "        # get data from dataloader. This is the thing that I get from the get_item\n",
        "        inputs, targets = batch\n",
        "\n",
        "        # move data to device\n",
        "        inputs, targets = inputs.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward pass\n",
        "        outputs = net(inputs)\n",
        "\n",
        "        # calculate loss\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        # loss gradient backpropagation\n",
        "        loss.backward() # I calculate the derivatives backwards\n",
        "\n",
        "        # net parameters update\n",
        "        optimizer.step() #I use the gradients to update the weights\n",
        "\n",
        "        # accumulate loss\n",
        "        loss_sum += loss.item()\n",
        "\n",
        "        # accumulate correct outputs (for accuracy calculation)\n",
        "        outputs_max = torch.argmax(outputs, dim=1) #predicted labels\n",
        "        targets_max = targets #torch.argmax(targets, dim=1)\n",
        "        correct += outputs_max.eq(targets_max).sum().float() # this is to find out how many predictions were correct\n",
        "\n",
        "    # step learning rate scheduler\n",
        "    scheduler.step() #we just need to keep track of the steps since the LR depends on it\n",
        "\n",
        "    # return average loss and accuracy\n",
        "    return loss_sum / len(dataloader), 100. * correct / len(dataset)\n"
      ],
      "metadata": {
        "id": "Z0Zd_yPrEMdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=30):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict()) #It keeps track of the parameters of the model in certain state\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'eval']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloader[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    preds = torch.argmax(outputs, dim=1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            if phase == 'train':\n",
        "              scheduler.step()\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "            \n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'eval' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "metadata": {
        "id": "yLRT9aFctJm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define test function\n",
        "# returns predictions\n",
        "def test(dataset, dataloader):\n",
        "\n",
        "    # switch to test mode\n",
        "    net.eval()  \n",
        "\n",
        "    # initialize predictions\n",
        "    predictions = torch.zeros(len(dataset), dtype=torch.int64)\n",
        "    sample_counter = 0\n",
        "\n",
        "    # do not accumulate gradients (faster)\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # test all batches\n",
        "        for batch in dataloader:\n",
        "\n",
        "            # get data from dataloader [ignore labels/targets as they are not used in test mode]\n",
        "            inputs = batch[0]\n",
        "\n",
        "            # move data to device\n",
        "            inputs = inputs.to(device, non_blocking=True)\n",
        "\n",
        "            # forward pass\n",
        "            outputs = net(inputs)\n",
        "\n",
        "            # store predictions\n",
        "            outputs_max = torch.argmax(outputs, dim=1)\n",
        "            for output in outputs_max:\n",
        "                predictions[sample_counter] = output\n",
        "                sample_counter += 1\n",
        "\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "OnYAcElltZhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_model(net, criterion, optimizer, scheduler, num_epochs=epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "SugDntlJSAgh",
        "outputId": "9d14e7ce-a493-4f5e-dfc3-9f4258b65897"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.0200 Acc: 0.9971\n",
            "eval Loss: 0.0189 Acc: 0.9971\n",
            "\n",
            "Epoch 2/30\n",
            "----------\n",
            "train Loss: 0.0191 Acc: 0.9971\n",
            "eval Loss: 0.0188 Acc: 0.9971\n",
            "\n",
            "Epoch 3/30\n",
            "----------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-77e86cb36ebe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-8dbef6b78b86>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0;31m# track history if only in train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-23f834181b59>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     31\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dropout probability has to be between 0 and 1, \"\u001b[0m \u001b[0;34m\"but got {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1279\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = test(test_features, dataloader_test)\n",
        "accuracy = 100. * predictions.eq(test_features.targets).sum().float() / len(test_features)\n",
        "print (\"Accuracy on test set is %.2f\" % accuracy)"
      ],
      "metadata": {
        "id": "Wy_vO9jx5cl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-6Xmx6L36K7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    # mean = np.array([0.485, 0.456, 0.406])\n",
        "    # std = np.array([0.229, 0.224, 0.225])\n",
        "    # inp = std * inp + mean\n",
        "    # inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "# Get a batch of training data\n",
        "# inputs, classes = next(iter(loader.rois[0]))\n",
        "\n",
        "# # Make a grid from batch\n",
        "# out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "# imshow(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "0jQMSj59ZRuX",
        "outputId": "049f0953-7e79-4662-9ae7-bb292c7d8f1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-79a5ed156283>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Get a batch of training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrois\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Make a grid from batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GfjBGhBEaSoh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}