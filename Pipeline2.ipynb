{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emyesme/CalcificationDetection/blob/Emily/Pipeline2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Libraries and Data Setup"
      ],
      "metadata": {
        "id": "kXWym_EKAKUN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries"
      ],
      "metadata": {
        "id": "P5KF-GomVYsN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Wlt8za56vXZ",
        "outputId": "2d43e469-5640-43bc-97a9-7dc0bff3dd90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (0.19.2)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.6.3)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.21.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (21.3)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.3.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2021.11.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.4.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (7.1.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->scikit-image) (3.0.8)\n"
          ]
        }
      ],
      "source": [
        "# just once to install opencv\n",
        "#!pip install opencv-python\n",
        "#!pip install matplotlib\n",
        "#!pip install numpy\n",
        "#!pip install google-colab\n",
        "\n",
        "#!pip install PyWavelets\n",
        "#!pip install image_dehazer\n",
        "!pip install -U scikit-image\n",
        "#!pip install fastprogress\n",
        "from fastprogress import master_bar, progress_bar\n",
        "\n",
        "# import opencv\n",
        "import cv2\n",
        "# import numpy\n",
        "import numpy as np\n",
        "import math\n",
        "# features module from scikit-image\n",
        "from skimage import feature\n",
        "import itertools\n",
        "#import show special for google colab\n",
        "from google.colab.patches import cv2_imshow\n",
        "#import plt for display\n",
        "import matplotlib.pyplot as plt\n",
        "# wavelet\n",
        "import pywt\n",
        "# combination of lists\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Drive Setup"
      ],
      "metadata": {
        "id": "XIR8JLtxAB3j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5i-G98GNpyYt",
        "outputId": "4f4ebd8c-e740-43d8-8eac-625602b283ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') # This will prompt for authorization."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We put a shortcut in our drive to the image processing folder for this."
      ],
      "metadata": {
        "id": "lPVc5BwPAacs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "5st-OLpSqZ6A"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "DATA_DIR = os.path.join('/content',\n",
        "                        'drive',\n",
        "                        'MyDrive',\n",
        "                        'Image Processing and Analysis 2022',\n",
        "                        'projects',\n",
        "                        'Calcification Detection',\n",
        "                        'dataset')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Setup"
      ],
      "metadata": {
        "id": "9qro11DuuHQ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#go into de directory of the images\n",
        "\n",
        "# this have 3 outputs root directory, the folders in the path and the files in the path.\n",
        "# we ignore _ the two first because we are not interested in those\n",
        "_, _, images = next(os.walk(os.path.join(DATA_DIR,'images')))\n",
        "_, _, breastMasks = next(os.walk(os.path.join(DATA_DIR,'masks')))\n",
        "_, _, groundTruths = next(os.walk(os.path.join(DATA_DIR, 'groundtruths')))\n",
        "\n",
        "images.sort()\n",
        "breastMasks.sort()\n",
        "groundTruths.sort()\n",
        "\n",
        "# read numbers of normal images\n",
        "normals = []\n",
        "with open(os.path.join(DATA_DIR,'normals.txt')) as f:\n",
        "    for line in f:\n",
        "        normals.append(line[:-1])"
      ],
      "metadata": {
        "id": "qVa4SLoMuJnG"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Google Colab Like a Pro"
      ],
      "metadata": {
        "id": "UrNskk4euP8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://medium.com/@robertbracco1/configuring-google-colab-like-a-pro-d61c253f7573#a642\n",
        "%%javascript\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\");\n",
        "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
        "}setInterval(ClickConnect,60000)"
      ],
      "metadata": {
        "id": "F95xA4V4uUZI",
        "outputId": "6502f800-eeda-45d9-e1d8-14f942362266",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "function ClickConnect(){\n",
              "console.log(\"Working\");\n",
              "document.querySelector(\"colab-toolbar-button#connect\").click()\n",
              "}setInterval(ClickConnect,60000)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "fLGkMjUYVev7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DeHazing Using Dark Channel Prior and Guided Filter"
      ],
      "metadata": {
        "id": "XYzla-c2R8l_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dehazing method proposed by the professor (also used in his paper)\n",
        "\n",
        "Taken from here:\n",
        "https://github.com/He-Zhang/image_dehaze\n",
        "Info on readme.md of the repo"
      ],
      "metadata": {
        "id": "0uY5uR3KSGBi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dark Channel"
      ],
      "metadata": {
        "id": "_9cQrJMPS5LT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here goes the theory behind this function "
      ],
      "metadata": {
        "id": "0E0GdS_BTOAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here goes inputs --> output types\n",
        "def DarkChannel(im,sz):\n",
        "    b,g,r = cv2.split(im)\n",
        "    dc = cv2.min(cv2.min(r,g),b);\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(sz,sz))\n",
        "    dark = cv2.erode(dc,kernel)\n",
        "    return dark"
      ],
      "metadata": {
        "id": "oahKNNk_TCQ1"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AtmLight"
      ],
      "metadata": {
        "id": "PYBQgzyNkKDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Possibly change to grayscale would be nice\n",
        "def AtmLight(im,dark):\n",
        "    [h,w] = im.shape[:2]\n",
        "    imsz = h*w\n",
        "    numpx = int(max(math.floor(imsz/1000),1))\n",
        "    darkvec = dark.reshape(imsz);\n",
        "    imvec = im.reshape(imsz,3);\n",
        "\n",
        "    indices = darkvec.argsort();\n",
        "    indices = indices[imsz-numpx::]\n",
        "\n",
        "    atmsum = np.zeros([1,3])\n",
        "    for ind in range(1,numpx):\n",
        "       atmsum = atmsum + imvec[indices[ind]]\n",
        "\n",
        "    A = atmsum / numpx;\n",
        "    return A"
      ],
      "metadata": {
        "id": "3o_LF4EXj7ut"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TransmissionEstimate"
      ],
      "metadata": {
        "id": "HgNCi3U-kNhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def TransmissionEstimate(im,A,sz):\n",
        "    omega = 0.95;# the closer to 1 the stronger the darkenning\n",
        "    im3 = np.empty(im.shape,im.dtype);\n",
        "\n",
        "    for ind in range(0,3):\n",
        "        im3[:,:,ind] = im[:,:,ind]/A[0,ind]\n",
        "\n",
        "    transmission = 1 - omega*DarkChannel(im3,sz);\n",
        "    return transmission"
      ],
      "metadata": {
        "id": "B9564anxkREK"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GuidedFilter"
      ],
      "metadata": {
        "id": "ujgwt8eakTwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Guidedfilter(im,p,r,eps):\n",
        "    mean_I = cv2.boxFilter(im,cv2.CV_64F,(r,r));\n",
        "    mean_p = cv2.boxFilter(p, cv2.CV_64F,(r,r));\n",
        "    mean_Ip = cv2.boxFilter(im*p,cv2.CV_64F,(r,r));\n",
        "    cov_Ip = mean_Ip - mean_I*mean_p;\n",
        "\n",
        "    mean_II = cv2.boxFilter(im*im,cv2.CV_64F,(r,r));\n",
        "    var_I   = mean_II - mean_I*mean_I;\n",
        "\n",
        "    a = cov_Ip/(var_I + eps);\n",
        "    b = mean_p - a*mean_I;\n",
        "\n",
        "    mean_a = cv2.boxFilter(a,cv2.CV_64F,(r,r));\n",
        "    mean_b = cv2.boxFilter(b,cv2.CV_64F,(r,r));\n",
        "\n",
        "    q = mean_a*im + mean_b;\n",
        "    return q;"
      ],
      "metadata": {
        "id": "pQwICn9skXtP"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TransmissionRefine"
      ],
      "metadata": {
        "id": "4tB3quNxkbJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def TransmissionRefine(im,et):\n",
        "    gray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY);\n",
        "    gray = np.float64(gray)/255;\n",
        "    r = 60;\n",
        "    eps = 0.0001;\n",
        "    t = Guidedfilter(gray,et,r,eps);\n",
        "\n",
        "    return t;"
      ],
      "metadata": {
        "id": "r_GHwktLkbkv"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Recover"
      ],
      "metadata": {
        "id": "6nOv5qYxkjqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Recover(im,t,A,tx = 0.1):\n",
        "    res = np.empty(im.shape,im.dtype);\n",
        "    t = cv2.max(t,tx);\n",
        "\n",
        "    for ind in range(0,3):\n",
        "        res[:,:,ind] = (im[:,:,ind]-A[0,ind])/t + A[0,ind]\n",
        "    return res"
      ],
      "metadata": {
        "id": "VuIef3qHkn5I"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### deHazingDarkChannelPriorPy"
      ],
      "metadata": {
        "id": "S_V-ibO6koPC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "v9lVjTTcoC2C"
      },
      "outputs": [],
      "source": [
        "def deHazingDarkChannelPriorPy(matrix, mask):\n",
        "\n",
        "    I = matrix.astype(np.float64)/255\n",
        " \n",
        "    dark = DarkChannel(I,15)\n",
        "    A = AtmLight(I,dark)\n",
        "    te = TransmissionEstimate(I,A,15)\n",
        "    t = TransmissionRefine(matrix,te)\n",
        "    J = Recover(I,t,A,0.1)\n",
        "    preprocessed = J\n",
        "    return preprocessed\n",
        "\n",
        "# image = cv2.imread(DATA_DIR+\"/images/53582422_3f0db31711fc9795_MG_R_ML_ANON.tif\")\n",
        "# dark, t, matrix, J = deHazingDarkChannelPriorPy(image, image)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Dilation"
      ],
      "metadata": {
        "id": "ZAa2ldjTlMWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def imgDilation(matrix):\n",
        "  kernel = np.ones((9,9), np.uint8)\n",
        "  img_dilation = cv2.dilate(matrix, kernel, iterations=3)\n",
        "  return img_dilation"
      ],
      "metadata": {
        "id": "8D4EdMZolL_j"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Other Tried Methods"
      ],
      "metadata": {
        "id": "KFc9qVWuu2ng"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CLAHE (adaptive histogram equalization)**\n",
        "  * CLAHE + dehazing = bad results, black image \n",
        "  * points less visible with CLAHE\n",
        "\n",
        "**Linear stretching**\n",
        "  * still missing linear streching\n",
        "  * The code goes on forever (high computational cost)\n",
        "\n"
      ],
      "metadata": {
        "id": "OY0FcYiDvfZG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Candidate Extraction"
      ],
      "metadata": {
        "id": "vNWyVrjyVvuW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Hessian-Matrix-Based Analysis"
      ],
      "metadata": {
        "id": "_BG3WCxXZNpv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hessian-matrix-based analysis or difference of gaussians (DoH) blob detection from skimage:\n",
        "\n",
        "https://scikit-image.org/docs/stable/api/skimage.feature.html?highlight=local%20binary%20pattern#skimage.feature.blob_doh"
      ],
      "metadata": {
        "id": "_FPkl7iJlJCC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "f0KHFD9fFC9y"
      },
      "outputs": [],
      "source": [
        "def candidateExtraction(matrix, mask):\n",
        "\n",
        "  from skimage import feature\n",
        "  \n",
        "  # returns x,y,sigma of the blob\n",
        "  blobs = feature.blob_doh(matrix,\n",
        "                           min_sigma=1,\n",
        "                           max_sigma=30,\n",
        "                           num_sigma=10,\n",
        "                           # The absolute lower bound for scale space maxima.\n",
        "                           # Local maxima smaller than threshold are ignored.\n",
        "                           # Reduce this to detect blobs with lower intensities.\n",
        "                           # If threshold_rel is also specified, whichever threshold is larger will be used.\n",
        "                           # If None, threshold_rel is used instead.\n",
        "                           threshold=0.005,\n",
        "                           # lower more sensible, more false positives bad also tinier calcifications detected\n",
        "                           overlap=0.5,\n",
        "                           log_scale=False,\n",
        "                           threshold_rel=None\n",
        "                           )\n",
        "  # taken from the documentation\n",
        "  # ...The downside is that this method can’t be used for detecting blobs of radius less than 3px\n",
        "  # due to the box filters used in the approximation of Hessian Determinant.\n",
        "  result = blobs\n",
        "  return result"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction"
      ],
      "metadata": {
        "id": "von-0yGEXbzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get Ground Truth for each patch\n",
        "def patchGroundTruth(candidate, groundTruth):\n",
        "\n",
        "  left = int((candidate[0] - candidate[2]) if ((candidate[0] - candidate[2]) > 0) else 0)\n",
        "  right = int((candidate[0] + candidate[2]) if ((candidate[0] + candidate[2]) < groundTruth.shape[0]) else groundTruth.shape[0])\n",
        "  top = int((candidate[1] - candidate[2]) if ((candidate[1] - candidate[2]) > 0) else 0)\n",
        "  bottom = int((candidate[1] + candidate[2]) if ((candidate[1] + candidate[2]) < groundTruth.shape[1]) else groundTruth.shape[1])\n",
        "\n",
        "  truePatch = groundTruth[left : right,\n",
        "                          top  : bottom]\n",
        "  sum = np.sum(truePatch)\n",
        "  if sum > 0:\n",
        "    return str(1)\n",
        "  else:\n",
        "    return str(0)"
      ],
      "metadata": {
        "id": "fe7aJb2YhZ9a"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Video tutorial on how to use GLCM:\n",
        "\n",
        "* https://www.youtube.com/watch?v=5x-CIHRmMNY\n",
        "\n",
        "Documentation and example on GLCM:\n",
        "\n",
        "* https://scikit-image.org/docs/dev/auto_examples/features_detection/plot_glcm.html\n",
        "\n",
        "Paper:\n",
        "\n",
        "*  https://ijcrr.com/uploads/3454_pdf.pdf\n",
        "\n",
        "GLCM Properties documentation:\n",
        "\n",
        "* https://scikit-image.org/docs/dev/api/skimage.feature.html#skimage.feature.graycoprops\n",
        "\n",
        "GLCM Gray co-matrix documentation:\n",
        "\n",
        "* https://stackoverflow.com/questions/54512617/creating-gray-level-co-occurrence-matrix-from-16-bit-image\n",
        "(why can't we have 16 bit type for the coocurrence matrix computation)\n",
        "\n",
        "* https://www.sciencedirect.com/topics/engineering/cooccurrence-matrix (simple explanation GLCM)"
      ],
      "metadata": {
        "id": "MfBTU_XZoIsZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Haar-Wavelet with GLCM\n",
        "Appl. Sci. 2019, 9, 5388; doi:10.3390/app9245388\n",
        "\n",
        "Method: apply the feature extraction with the glcm to each haar wavelet decomposition result\n",
        "\n",
        "*Because of their small size and their high degree of localization, microcalcifications represent high-spatial frequencies in the image. The wavelet transform is an attractive option for the detection of high-spatial-frequency components of an image because it can spatially localize high-frequency components. Hence, it was used by many authors for the segmentation of microcalcifications. 15–27*\n",
        "Source: DOI: 10.1118/1.3121511\n"
      ],
      "metadata": {
        "id": "PUWQRdESsaXf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "23WbyaI2FhzF"
      },
      "outputs": [],
      "source": [
        "def featuresExtractionHaarWavelet(matrix, candidates, features, mask, groundTruth, image, folder):\n",
        "\n",
        "  # no candidates, no extraction needed\n",
        "  if (len(candidates) == 0):\n",
        "    return []\n",
        "\n",
        "  # angles\n",
        "  angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
        "\n",
        "  flag = True\n",
        "  for index, candidate in enumerate(progress_bar(candidates)):\n",
        "    \n",
        "    distances = [1]# probably we need bigger\n",
        "\n",
        "    # to use them as coordinates they have to be integers\n",
        "    candidate = candidate.astype(np.int64)\n",
        "\n",
        "    # candidates are y,x and sigma\n",
        "    # tolerance to the window\n",
        "    n = 3\n",
        "    left = int((candidate[0] - candidate[2] - n) if ((candidate[0] - candidate[2] - n) > 0) else 0)\n",
        "    right = int((candidate[0] + candidate[2] + n) if ((candidate[0] + candidate[2] + n) < matrix.shape[0]) else matrix.shape[0])\n",
        "    top = int((candidate[1] - candidate[2] - n) if ((candidate[1] - candidate[2] - n) > 0) else 0)\n",
        "    bottom = int((candidate[1] + candidate[2] + n) if ((candidate[1] + candidate[2] + n) < matrix.shape[1]) else matrix.shape[1])\n",
        "\n",
        "    patchCandidate = matrix[left: right,\n",
        "                            top : bottom]\n",
        "\n",
        "    # graycomatrix, glcm, receive unsigned integer type\n",
        "    patchCandidate = patchCandidate.astype(np.uint8)\n",
        "\n",
        "    #Wavelet Transform\n",
        "\n",
        "    ## haar wavelet \n",
        "    #Apply GLCM on LH, HL, HH\n",
        "\n",
        "    coeffs2 = pywt.dwt2(patchCandidate, 'haar')\n",
        "\n",
        "    # low-low, low-high, high-low, high-high\n",
        "    (LL, (LH, HL, HH)) = coeffs2\n",
        "\n",
        "    # LL just give information about the details not the edges so unnecessary\n",
        "\n",
        "    LH = LH.astype(np.uint8)\n",
        "    HL = HL.astype(np.uint8)\n",
        "    HH = HH.astype(np.uint8)\n",
        "\n",
        "    haarDecomposes = [LH, HL, HH]\n",
        "\n",
        "    for i, haarDecompose in enumerate(haarDecomposes):\n",
        "\n",
        "      dictFeatures = {}\n",
        "      dictFeatures = {'name': 'patch_' + str(index) + '_haar_' + str(i) + '_surf_' + str(image.split(\".\")[0]),\n",
        "                      'label': patchGroundTruth(candidate, groundTruth)}\n",
        "\n",
        "      # combination of distances and angles as couples of values\n",
        "      distAngle = list(itertools.product(distances, angles))\n",
        "\n",
        "      for distanceAngle in distAngle:\n",
        "\n",
        "        distance = distanceAngle[0]\n",
        "        angle = distanceAngle[1]\n",
        "\n",
        "        # get the degree to use it as name for the column\n",
        "        name = str(angle*(180.0/np.pi))\n",
        "\n",
        "        # input image, distance in pixels, angles\n",
        "        glcm = feature.graycomatrix(haarDecompose, [ distance ], [ angle ])\n",
        "\n",
        "        # properties\n",
        "        dictFeatures['contrast'+ str(distance) + name] = feature.graycoprops(glcm, 'contrast')[0][0]\n",
        "        dictFeatures['dissimilarity' + str(distance) + name] = feature.graycoprops(glcm, 'dissimilarity')[0][0]\n",
        "        dictFeatures['homogeneity' + str(distance) + name] = feature.graycoprops(glcm, 'homogeneity')[0][0]\n",
        "        dictFeatures['energy' + str(distance) + name] = feature.graycoprops(glcm, 'energy')[0][0]\n",
        "        dictFeatures['correlation' + str(distance) + name] = feature.graycoprops(glcm, 'correlation')[0][0]\n",
        "        dictFeatures['ASM' + str(distance) + name] = feature.graycoprops(glcm, 'ASM')[0][0]\n",
        "\n",
        "      # add to the dataframe the features for this patch\n",
        "      features = features.append(dictFeatures, ignore_index=True)\n",
        "\n",
        "  # save in the csv\n",
        "  writeFeatures(features, flag, folder, image, 'haar_glcm')\n",
        "\n",
        "  return features"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def writeFeatures(features, flag, folder, image, name):\n",
        "  if(flag):\n",
        "    features.to_csv(os.path.join('/content',\n",
        "                                 'drive',\n",
        "                                 'MyDrive',\n",
        "                                 'Results',\n",
        "                                 folder,\n",
        "                                 str(image.split('.')[0]) + '_'+ name + '.csv'),\n",
        "                    mode='a',\n",
        "                    index=False)\n",
        "    flag = False\n",
        "  else:\n",
        "    features.to_csv(os.path.join('/content',\n",
        "                                 'drive',\n",
        "                                 'MyDrive',\n",
        "                                 'Results',\n",
        "                                 folder,\n",
        "                                 str(image.split('.')[0]) + '_'+ name + '.csv'),\n",
        "                  mode='a',\n",
        "                  header=False,\n",
        "                  index=False)\n",
        "  return flag"
      ],
      "metadata": {
        "id": "KacVrfAgo1Lr"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connected Components"
      ],
      "metadata": {
        "id": "rYRi_ffVWClo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "d7G2psxqargQ"
      },
      "outputs": [],
      "source": [
        "# function to get connected components of the ground truth binary image\n",
        "def componentsStatsGroundTruth(matrix):\n",
        "    # getting the info of the components in the ground truth\n",
        "    # second value is connectivity 4 or 8\n",
        "    connectedComponentsGroundTruth = cv2.connectedComponentsWithStats(matrix, 8, cv2.CV_32S)\n",
        "\n",
        "    # Get the results\n",
        "    # The first cell is the number of labels\n",
        "    num_labels = connectedComponentsGroundTruth[0]\n",
        "    # The second cell is the label matrix\n",
        "    labels = connectedComponentsGroundTruth[1]\n",
        "    # The third cell is the stat matrix\n",
        "    stats = connectedComponentsGroundTruth[2]\n",
        "    # The fourth cell is the centroid matrix\n",
        "    centroids = connectedComponentsGroundTruth[3]\n",
        "\n",
        "    return num_labels, labels, stats, centroids"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Show Images"
      ],
      "metadata": {
        "id": "pqItorT9Wr06"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "G6mejNA1fgIq"
      },
      "outputs": [],
      "source": [
        "from matplotlib.patches import Circle\n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "# function to draw the grid to display\n",
        "def display_grid(figure, axis, img, imgGroundTruth, preprocessed, candidates, features):\n",
        "  # draw in the axis the img\n",
        "  axis[0][0].imshow(img)\n",
        "  # switch off the axis of the plot\n",
        "  axis[0][0].axis('off')\n",
        "  # set a title for the plot\n",
        "  axis[0][0].set_title('Image')\n",
        "\n",
        "  axis[0][1].imshow(imgGroundTruth, cmap='gray')\n",
        "  axis[0][1].axis('off')\n",
        "  axis[0][1].set_title('Ground Truth')\n",
        "\n",
        "  axis[0][2].imshow(imgMask)\n",
        "  axis[0][2].axis('off')\n",
        "  axis[0][2].set_title('Breast Mask')\n",
        "\n",
        "  axis[1][0].imshow(preprocessed, cmap='gray')\n",
        "  axis[1][0].axis('off')\n",
        "  axis[1][0].set_title('Preprocessed')\n",
        "\n",
        "  # draw candidates as circles\n",
        "  axis[1][1].imshow(preprocessed, cmap='gray')\n",
        "  axis[1][1].axis('off')\n",
        "  axis[1][1].set_title('Candidates')\n",
        "\n",
        "  # Now, loop through coord arrays, and create a circle at each x,y pair\n",
        "  for y,x,sigma in candidates:\n",
        "\n",
        "    # blue circle on the candidate\n",
        "    blob = Circle((x,y), sigma*5, color='blue', fill=False)\n",
        "    axis[1][1].add_patch(blob)\n",
        "\n",
        "    # red squares in the patches extracted\n",
        "    rect=mpatches.Rectangle((x,y),sigma,sigma, \n",
        "                        fill=False,\n",
        "                        color=\"red\",\n",
        "                       linewidth=2)\n",
        "    axis[1][1].add_patch(rect)\n",
        "\n",
        "  axis[1][2].imshow(imgGroundTruth, cmap='gray')\n",
        "  axis[1][2].axis('off')\n",
        "  axis[1][2].set_title('compare with ground truth and candidates')\n",
        "\n",
        "  # Now, loop through coord arrays, and create a circle at each x,y pair\n",
        "  for y,x,sigma in candidates:\n",
        "    blob = Circle((x,y), sigma, color='blue', fill=False)\n",
        "    axis[1][2].add_patch(blob)\n",
        "  \n",
        "  return figure, axis"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "7GHlP95OW6e6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "id": "qqqX2PGi6-X8",
        "outputId": "312133d2-bde7-4560-d8d8-16dd631e059f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='4' class='' max='410' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      0.98% [4/410 01:30<2:32:39]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='23' class='' max='23' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [23/23 00:01<00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='16' class='' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [16/16 00:01<00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='32' class='' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [32/32 00:02<00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='22' class='' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [22/22 00:01<00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import copy\n",
        "import pandas as pd\n",
        "\n",
        "#go through the image files \n",
        "for image, breastMask, groundTruth in zip(progress_bar(images), breastMasks, groundTruths):\n",
        "\n",
        "  # to save the features generated with the glcm\n",
        "  features = pd.DataFrame(dtype=np.float64)\n",
        "\n",
        "  # 20588020, 7717, 5328, 3787, 5725, 3859, 6934, 50995872\n",
        "  digits = '5328'\n",
        "\n",
        "  #if ((digits in image) and (digits in breastMask) and ('mask' in breastMask)):\n",
        "  if ('mask' in breastMask):\n",
        "  #if image not in already:\n",
        "\n",
        "    #upload images\n",
        "    img = cv2.imread(os.path.join(DATA_DIR,'images',image))\n",
        "    imgMask = cv2.imread(os.path.join(DATA_DIR, 'masks', breastMask))\n",
        "    imgGroundTruth = cv2.imread(os.path.join(DATA_DIR, 'groundtruths', image), cv2.IMREAD_GRAYSCALE)\n",
        "    imgCopy = copy.deepcopy(img)\n",
        "\n",
        "    # preprocessing # \n",
        "\n",
        "    preprocessed = deHazingDarkChannelPriorPy(imgCopy, imgMask)\n",
        "    preprocessedDil = imgDilation(preprocessed)\n",
        "\n",
        "    # candidate extraction #\n",
        "\n",
        "    copyPreprocessedDil = copy.deepcopy(preprocessedDil)\n",
        "    copyPreprocessedDil = copyPreprocessedDil.astype(np.float32)\n",
        "    copyPreprocessedDil = cv2.cvtColor(copyPreprocessedDil, cv2.COLOR_BGR2GRAY)\n",
        "    candidates = candidateExtraction(copyPreprocessedDil, imgMask)\n",
        "\n",
        "    # feature extraction #\n",
        "\n",
        "    copyPreprocessed = copy.deepcopy(preprocessed)\n",
        "    copyPreprocessed = copyPreprocessed.astype(np.float32)\n",
        "    copyPreprocessed = cv2.cvtColor(copyPreprocessed, cv2.COLOR_BGR2GRAY)\n",
        "    features = featuresExtractionHaarWavelet(copyPreprocessed, candidates, features, imgMask, imgGroundTruth, image, 'dehazingDC_GF+Dilation+DoH+(Haar+GLCM)')\n",
        "\n",
        "    # ML must be applied for the classification of the features extracted\n",
        "\n",
        "    ################ ERASE MEMORY\n",
        "    # import gc\n",
        "    # del features\n",
        "    # del preprocessed\n",
        "    # del candidates\n",
        "    # # del blobs\n",
        "    # del copyPreprocessed\n",
        "    # del imgCopy\n",
        "    # del img\n",
        "    # del imgMask\n",
        "    # del imgGroundTruth\n",
        "    # gc.collect()\n",
        "    ############################\n",
        "\n",
        "    # end image processing part #\n",
        "\n",
        "    # display related #\n",
        "\n",
        "    # matrix of plots and size of the figure\n",
        "    # figure, axis = plt.subplots(2, 3, figsize=(15,15))\n",
        "    # display_grid(figure, axis, img, imgGroundTruth, preprocessed, candidates, features)\n",
        "    # plt.subplots_adjust(wspace=0, hspace=0)\n",
        "\n",
        "    # # # display figure with image\n",
        "    # plt.show() "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CONCLUSIONS FOR PREPROCESSING"
      ],
      "metadata": {
        "id": "VRSMyeuNzT_W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* still missing quantum noise supression\n",
        "\n",
        "* details in the phd defense file\n",
        "\n",
        "* Observations from the results:\n",
        "    * fiber intersections may also appear as bright spots (false positives)\n",
        "\n",
        "* THINGS WE NOTICE BETWEEN BOTH DEHAZING METHODS\n",
        "    * Better suppression of fatty tissue (noise) and greater enhancement of brightness of desired feature (microcalcifications)\n",
        "    * sometimes for the other dehazing method black patches become present in the fatty tissue\n",
        "    * this did not happen in the dehazing with dark channel prior (and guided filter)\n",
        "    * sharper\n",
        "    * enhances the contrast and details\n",
        "\n",
        "* Observations from the results:\n",
        "    * images with pectoral muscule cause false positives"
      ],
      "metadata": {
        "id": "7KoeGI1Nzbtn"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Pipeline2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}