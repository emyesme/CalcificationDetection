{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Counting.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emyesme/CalcificationDetection/blob/Emily/Counting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NKA_5syitsu",
        "outputId": "cc824999-d3ee-4e5b-9c31-b2ae3aaa7941"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "#!pip install fastprogress\n",
        "from fastprogress import master_bar, progress_bar\n",
        "#!pip install tqdm\n",
        "from tqdm.notebook import tqdm_notebook"
      ],
      "metadata": {
        "id": "yXLPF5lyl6ia"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def calculateFROC(groundTruthsDataFrame, normals, candidates):\n",
        "  # evaluation froc curve #\n",
        "\n",
        "  #counting\n",
        "  evaluationList = []\n",
        "\n",
        "  fn = 0 # false negative, for the blobs that do not belong to any component\n",
        "\n",
        "  positive_candidates = 0\n",
        "  flag = False\n",
        "\n",
        "  for index, row in tqdm_notebook(groundTruthsDataFrame.iterrows()):\n",
        "\n",
        "    imageKey = row['name'].split('_')[0]\n",
        "\n",
        "    # list of features found with y,x and sigma\n",
        "    candidatesImg = candidates.loc[candidates['name'].str.contains(imageKey, regex=False)]\n",
        "\n",
        "    candidates_number = len(candidatesImg)\n",
        "          \n",
        "    for gtComponent in range(int(row.num_labels)):\n",
        "      matches = []\n",
        "      evaluationList = []\n",
        "      \n",
        "      for index2, candidate in candidatesImg.iterrows():\n",
        "\n",
        "        if (imageKey in normals):\n",
        "          continue\n",
        "        # is the image a normal image?\n",
        "\n",
        "        stat = eval(row.stats)[gtComponent]\n",
        "\n",
        "        # top left is the 0,0 of the image\n",
        "        \n",
        "        left = stat['leftmost_x']\n",
        "        right = stat['leftmost_x'] + stat['hor_size']\n",
        "\n",
        "        top = stat['topmost_y']\n",
        "        bottom = stat['topmost_y'] + stat['vert_size']\n",
        "\n",
        "        if (left == 0) and (top ==0) and (gtComponent==0): #This is background so we can skip it\n",
        "          continue\n",
        "\n",
        "        if ( candidate.x >= left ) and ( candidate.x <= right ) and ( candidate.y >= top ) and ( candidate.y <= bottom ): #This is to find if the candidate is whithin the groundtruth component\n",
        "          matches.append(candidate.x)\n",
        "\n",
        "      if len(matches) == 1:\n",
        "        positive_candidates += 1\n",
        "      elif len(matches) > 1:\n",
        "        positive_candidates += 1\n",
        "      elif gtComponent > 0: #The component is not background\n",
        "        fn = fn+1\n",
        "\n",
        "    evaluationList.append([imageKey, int(row.num_labels)-1, candidates_number, positive_candidates])\n",
        "    positive_candidates = 0\n",
        "\n",
        "    dfEvaluationList= pd.DataFrame(evaluationList, columns=['key', 'num_labels_gt', 'candidates','positive candidates'])\n",
        "\n",
        "    flag = writeFile(dfEvaluationList, flag)\n",
        "\n",
        "    del dfEvaluationList\n",
        "    del evaluationList\n"
      ],
      "metadata": {
        "id": "AUoWwSfCuNns"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def writeFile(df, flag):\n",
        "  if(flag):\n",
        "    df.to_csv(os.path.join('/content',\n",
        "                                 'drive',\n",
        "                                 'MyDrive',\n",
        "                                 'Results',\n",
        "                                 'countpipeline8.csv'),\n",
        "                    mode='a',\n",
        "                    index=False)\n",
        "    flag = False\n",
        "  else:\n",
        "    df.to_csv(os.path.join('/content',\n",
        "                                 'drive',\n",
        "                                 'MyDrive',\n",
        "                                 'Results',\n",
        "                                 'countpipeline8.csv'),\n",
        "                  mode='a',\n",
        "                  header=False,\n",
        "                  index=False)\n",
        "  return flag"
      ],
      "metadata": {
        "id": "rwYk7HycGRqH"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from everything\n",
        "RESULTS_DIR = os.path.join('/content',\n",
        "                        'drive',\n",
        "                        'MyDrive',\n",
        "                        'Results', \n",
        "                        '8.dehazingDil+DoG+GLCM')\n",
        "                        #'4.dehazingDC+DoH(0.0005)+GLCM')\n",
        "\n",
        "DATA_DIR = os.path.join('/content',\n",
        "                        'drive',\n",
        "                        'MyDrive',\n",
        "                        'Image Processing and Analysis 2022',\n",
        "                        'projects',\n",
        "                        'Calcification Detection',\n",
        "                        'dataset')\n",
        "\n",
        "gt = pd.read_csv(os.path.join('/content',\n",
        "                              'drive',\n",
        "                              'MyDrive',\n",
        "                              'Results',\n",
        "                              'groundTruthStats.csv'))\n",
        "\n",
        "# read numbers of normal images\n",
        "normals = []\n",
        "with open(os.path.join(DATA_DIR,'normals.txt')) as f:\n",
        "    for line in f:\n",
        "        normals.append(line[:-1])\n",
        "\n",
        "results_file = os.listdir(RESULTS_DIR)  \n",
        "dataset = os.listdir(os.path.join(DATA_DIR,\"images\"))\n",
        "candidates = pd.DataFrame()\n",
        "\n",
        "for result in results_file:\n",
        "    fileCandidate = pd.read_csv(os.path.join(RESULTS_DIR,result))\n",
        "    candidates = candidates.append(fileCandidate, ignore_index=True)\n",
        "\n",
        "calculateFROC(gt, normals, candidates)\n",
        "# df.to_csv(os.path.join('/content',\n",
        "#                                 'drive',\n",
        "#                                 'MyDrive',\n",
        "#                                 'Results',\n",
        "#                                 'countpipeline4.csv'))"
      ],
      "metadata": {
        "id": "YNWZDt6uj4s0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vl06rWhJuliU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RESTARTING FROM A PREVIOUS EXECUTION\n",
        "\n",
        "already = pd.read_csv(os.path.join('/content',\n",
        "                        'drive',\n",
        "                        'MyDrive',\n",
        "                        'Results',\n",
        "                        'countpipeline8.csv'))\n",
        "\n",
        "already = already['key'].map(str)\n",
        "already = already.tolist()\n",
        "\n",
        "\n",
        "\n",
        "RESULTS_DIR = os.path.join('/content',\n",
        "                        'drive',\n",
        "                        'MyDrive',\n",
        "                        'Results', \n",
        "                        '8.dehazingDil+DoG+GLCM')\n",
        "                        #'4.dehazingDC+DoH(0.0005)+GLCM')\n",
        "\n",
        "DATA_DIR = os.path.join('/content',\n",
        "                        'drive',\n",
        "                        'MyDrive',  \n",
        "                        'Image Processing and Analysis 2022',\n",
        "                        'projects',\n",
        "                        'Calcification Detection',\n",
        "                        'dataset')\n",
        "\n",
        "gt = pd.read_csv(os.path.join('/content',\n",
        "                              'drive',\n",
        "                              'MyDrive',\n",
        "                              'Results',\n",
        "                              'groundTruthStats.csv'))\n",
        "\n",
        "gt = gt['name'].map(str).tolist()\n",
        "all = []\n",
        "for gtrow in gt:\n",
        "  all.append(gtrow.split(\"_\")[0])\n",
        "\n",
        "missing =list(set(all)-set(already))\n",
        "\n",
        "# read numbers of normal images\n",
        "normals = []\n",
        "with open(os.path.join(DATA_DIR,'normals.txt')) as f:\n",
        "    for line in f:\n",
        "        normals.append(line[:-1])\n",
        "\n",
        "results_file = os.listdir(RESULTS_DIR)  \n",
        "dataset = os.listdir(os.path.join(DATA_DIR,\"images\"))\n",
        "candidates = pd.DataFrame()\n",
        "\n",
        "gtShort = pd.DataFrame()\n",
        "\n",
        "for image in dataset:\n",
        "  if image.split('_')[0] in missing:\n",
        "    \n",
        "    gtRow = gt.loc[gt['name'].str.contains(image, regex=False)]\n",
        "    gtShort = gtShort.append(gtRow)\n",
        "    fileCandidate = pd.read_csv(os.path.join(RESULTS_DIR,image[:-4]+'_features.csv'))\n",
        "    candidates = candidates.append(fileCandidate, ignore_index=True)\n",
        "    del gtRow\n",
        "\n",
        "# gtShort = gtShort.sample(n=20)\n",
        "\n",
        "print(len(gtShort))\n",
        "\n",
        "calculateFROC(gtShort, normals, candidates)\n"
      ],
      "metadata": {
        "id": "J7ZG436Rulqi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}