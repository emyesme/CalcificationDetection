{"cells":[{"cell_type":"markdown","metadata":{"id":"2R2T-8DOMq8L"},"source":["# Libraries and more"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":103113,"status":"ok","timestamp":1657120088437,"user":{"displayName":"EMILY ESMERALDA CARVAJAL CAMELO","userId":"02914831594555779435"},"user_tz":-120},"id":"an6KUl2OywBT","outputId":"a7444523-95dd-4a02-bc02-36a706826383"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3936,"status":"ok","timestamp":1657120092336,"user":{"displayName":"EMILY ESMERALDA CARVAJAL CAMELO","userId":"02914831594555779435"},"user_tz":-120},"id":"ED5f8LDCvuHB","outputId":"1db1c0f6-3857-432a-bbc4-7a5b5ce5684e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (0.18.3)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.3.0)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2021.11.2)\n","Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.4.1)\n","Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (3.2.2)\n","Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (1.21.6)\n","Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (7.1.2)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.4.1)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image) (2.6.3)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (3.0.9)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.4.3)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (4.1.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.15.0)\n"]}],"source":["#!pip install opencv-python\n","#!pip install matplotlib\n","#!pip install numpy\n","!pip install scikit-image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dcdVCA6WM3Rh"},"outputs":[],"source":["import cv2\n","import math\n","import numpy as np\n","import pywt\n","import os\n","import copy\n","import pandas as pd\n","\n","from skimage.feature import local_binary_pattern\n","from skimage import measure, data, feature\n","from scipy.stats import kurtosis, skew\n","from math import sqrt\n","from matplotlib import pyplot as plt\n","from matplotlib.patches import Circle\n","from fastprogress import master_bar, progress_bar"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Nnf63TdSXZd"},"outputs":[],"source":["# variables\n","\n","DATA_DIR = os.path.join('/content',\n","                        'drive',\n","                        'MyDrive',\n","                        'Image Processing and Analysis 2022',\n","                        'projects',\n","                        'Calcification Detection',\n","                        'dataset')\n","\n","_, _, images = next(os.walk(os.path.join(DATA_DIR,'images')))\n","_, _, groundTruths = next(os.walk(os.path.join(DATA_DIR, 'groundtruths')))\n","\n","images.sort()\n","groundTruths.sort()\n","\n","# read numbers of normal images\n","normals = []\n","with open(os.path.join(DATA_DIR,'normals.txt')) as f:\n","    for line in f:\n","        normals.append(line[:-1])"]},{"cell_type":"markdown","metadata":{"id":"MRZOIfVQHrM_"},"source":["# Functions for Image Processing"]},{"cell_type":"markdown","metadata":{"id":"p2yUjSTALLF8"},"source":["## Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"tTpsjv6OH1Tg"},"source":["For preprocessing we have several steps options:\n","\n","\n","1.   Dehazing with Dark Channel Prior and Guided Filter\n","2.   CLAHE (contrast limited adaptive histogram equalization)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"XYzla-c2R8l_"},"source":["### DeHazing Using Dark Channel Prior and Guided Filter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oahKNNk_TCQ1"},"outputs":[],"source":["# Here goes inputs --> output types\n","def DarkChannel(im,sz):\n","    b,g,r = cv2.split(im)\n","    dc = cv2.min(cv2.min(r,g),b);\n","    kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(sz,sz))\n","    dark = cv2.erode(dc,kernel)\n","    return dark"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3o_LF4EXj7ut"},"outputs":[],"source":["def AtmLight(im,dark):\n","    [h,w] = im.shape[:2]\n","    imsz = h*w\n","    numpx = int(max(math.floor(imsz/1000),1))\n","    darkvec = dark.reshape(imsz);\n","    imvec = im.reshape(imsz,3);\n","\n","    indices = darkvec.argsort();\n","    indices = indices[imsz-numpx::]\n","\n","    atmsum = np.zeros([1,3])\n","    for ind in range(1,numpx):\n","       atmsum = atmsum + imvec[indices[ind]]\n","\n","    A = atmsum / numpx;\n","    return A"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B9564anxkREK"},"outputs":[],"source":["def TransmissionEstimate(im,A,sz):\n","    omega = 0.95\n","    im3 = np.empty(im.shape,im.dtype)\n","\n","    for ind in range(0,3):\n","        im3[:,:,ind] = im[:,:,ind]/A[0,ind]\n","\n","    transmission = 1 - omega*DarkChannel(im3,sz)\n","    return transmission"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pQwICn9skXtP"},"outputs":[],"source":["def Guidedfilter(im,p,r,eps):\n","    mean_I = cv2.boxFilter(im,cv2.CV_64F,(r,r));\n","    mean_p = cv2.boxFilter(p, cv2.CV_64F,(r,r));\n","    mean_Ip = cv2.boxFilter(im*p,cv2.CV_64F,(r,r));\n","    cov_Ip = mean_Ip - mean_I*mean_p;\n","\n","    mean_II = cv2.boxFilter(im*im,cv2.CV_64F,(r,r));\n","    var_I   = mean_II - mean_I*mean_I;\n","\n","    a = cov_Ip/(var_I + eps);\n","    b = mean_p - a*mean_I;\n","\n","    mean_a = cv2.boxFilter(a,cv2.CV_64F,(r,r));\n","    mean_b = cv2.boxFilter(b,cv2.CV_64F,(r,r));\n","\n","    q = mean_a*im + mean_b;\n","    return q;"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r_GHwktLkbkv"},"outputs":[],"source":["def TransmissionRefine(im,et):\n","    gray = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY);\n","    gray = np.float64(gray)/255;\n","    r = 60;\n","    eps = 0.0001;\n","    t = Guidedfilter(gray,et,r,eps);\n","    return t;"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VuIef3qHkn5I"},"outputs":[],"source":["def Recover(im,t,A,tx = 0.1):\n","    res = np.empty(im.shape,im.dtype);\n","    t = cv2.max(t,tx);\n","    for ind in range(0,3):\n","        res[:,:,ind] = (im[:,:,ind]-A[0,ind])/t + A[0,ind]\n","    return res"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s9xF8v5WS5V_"},"outputs":[],"source":["def deHazingDarkChannelPrior(matrix):\n","\n","  I = matrix.astype(np.float64)/255\n","\n","  dark = DarkChannel(I,15)\n","  A = AtmLight(I,dark)\n","  te = TransmissionEstimate(I,A,15)\n","  t = TransmissionRefine(matrix,te)\n","  J = Recover(I,t,A,0.1)\n","  preprocessed = J\n","  return preprocessed"]},{"cell_type":"markdown","metadata":{"id":"TGh49rq8MvPt"},"source":["### CLAHE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J4nRkl0aM00c"},"outputs":[],"source":["def imgCLAHE(matrix):\n","  matrix = matrix.astype(np.uint16)\n","  clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n","  cl1 = clahe.apply(matrix)\n","  return cl1"]},{"cell_type":"markdown","metadata":{"id":"1Rpfjyp7IcDp"},"source":["## Candidate Extraction"]},{"cell_type":"markdown","metadata":{"id":"_BG3WCxXZNpv"},"source":["### Determinant of Hessian"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f0KHFD9fFC9y"},"outputs":[],"source":["def candidateExtractionDoH(matrix):\n","  \n","  # returns x,y,sigma of the blob\n","  blobs = feature.blob_doh(matrix,\n","                           min_sigma=1,\n","                           max_sigma=30,\n","                           num_sigma=10,\n","                           threshold=0.005,\n","                           # lower more sensible, more false positives bad also tinier calcifications detected\n","                           overlap=0.5,\n","                           log_scale=False,\n","                           threshold_rel=None\n","                           )\n","  # taken from the documentation\n","  # ...The downside is that this method canâ€™t be used for detecting blobs of radius less than 3px\n","  # due to the box filters used in the approximation of Hessian Determinant.\n","  result = blobs\n","  return result"]},{"cell_type":"markdown","metadata":{"id":"Hukzu-tbZaLh"},"source":["### Difference of Gaussians"]},{"cell_type":"markdown","metadata":{"id":"CKxr60QUNH6z"},"source":["In difference of gaussians for candidate extraction we have different configuration of parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CK8xuxdkZEwU"},"outputs":[],"source":["# studied options:\n","# option 1:\n","# min_sigma=0.0001\n","# max_sigma=30,\n","# threshold=0.04\n","\n","# option 2:\n","# min_sigma=0.005\n","# max_sigma=50,\n","# threshold=0.04\n","\n","# default option 1\n","def candidateExtractionDoG(matrix, minSigma=0.0001, maxSigma=30, threshold=0.04):\n","\n","  blobs = feature.blob_dog(matrix,\n","                           min_sigma=minSigma,\n","                           max_sigma=maxSigma,\n","                           threshold=threshold)\n","\n","  # https://scikit-image.org/docs/stable/auto_examples/features_detection/plot_blob.html\n","  blobs[:, 2] = blobs[:, 2] * sqrt(2) \n","\n","  result = blobs\n","  return result"]},{"cell_type":"markdown","metadata":{"id":"i2m7BWWNIdHW"},"source":["## Feature Extraction"]},{"cell_type":"markdown","metadata":{"id":"wFJjMz1bTLf4"},"source":["### Labelling patches"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hv2vOS8WS5qX"},"outputs":[],"source":["# Get Ground Truth for each patch\n","def patchGroundTruth(top, bottom, left, right, groundTruth):\n","  result = str(0)\n","  truePatch = groundTruth[top : bottom,\n","                          left : right]\n","  \n","  sum = np.sum(truePatch)\n","\n","  if sum > 0:\n","    result = str(1)\n","  \n","  return result"]},{"cell_type":"markdown","metadata":{"id":"IEVxyawzTOjW"},"source":["### First Order Statistic Features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Wyy09aUTOK8"},"outputs":[],"source":["def functionFeatures(patch):\n","  import scipy\n","  # 2) Parameters\n","  roi = patch.ravel()\n","  level_min = 0\n","  level_max = max(roi)\n","  Ng = (level_max - level_min) + 1\n","  bins = Ng\n","  \n","  # 3) Calculate Histogram H inside ROI\n","  H = np.histogram(roi, bins=bins, range=[level_min, level_max], density=True)[0]\n","\n","  # 4) Calculate Features\n","  fos = {}\n","  i = np.arange(0,bins)\n","  # 0 - mean\n","  fos[\"Mean\"] = np.mean(roi)\n","  # 1 - variance\n","  fos[\"Variance\"] = np.var(roi)\n","  # 2 - median\n","  fos[\"Median\"] = np.median(roi) \n","  # 3 - mode\n","  fos[\"Mode\"] = scipy.stats.mode(roi)[0][0]\n","  # 4 - skewness\n","  fos['skewness'] = skew(roi)\n","  # 5 - kurtosis\n","  fos['kurtosis'] = kurtosis(roi)\n","  # 6 - energy\n","  fos[\"Energy\"] = sum(np.multiply(H,H))\n","  # 7 - entropy\n","  fos[\"Entropy\"] = -sum(np.multiply(H,np.log(H+1e-16)))##################\n","  # 8 - minimal gray level\n","  fos[\"MinimalGrayLevel\"] = min(roi)\n","  # 9 - maximal gray level\n","  fos[\"MaximalGrayLevel\"] = max(roi)\n","  # 10 - coefficient of variation\n","  fos[\"CoefficientOfVariation\"] = np.sqrt(fos[\"Median\"]) / fos[\"Mean\"]\n","  # 11 - 10 percentile\n","  fos[\"10Percentile\"] = np.percentile(roi,10) \n","  # 12 - 25 percentile\n","  fos[\"25Percentile\"] = np.percentile(roi,25)  \n","  # 13 - 75 percentile\n","  fos[\"75Percentile\"] = np.percentile(roi,75) \n","  # 14 - 90 percentile\n","  fos[\"90Percentile\"] = np.percentile(roi,90) \n","  # 15 - histogram width\n","  fos[\"HistogramWidth\"] = fos[\"90Percentile\"] - fos[\"10Percentile\"]\n","\n","  return fos"]},{"cell_type":"markdown","metadata":{"id":"R5ndm72JTg9d"},"source":["### More Features for the Co-ocurrency matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l7yReQ6PTht9"},"outputs":[],"source":["def ProbSumDiff(glcm):\n","  resultSum = np.zeros(glcm.shape[0] * 2)\n","  resultDiff = np.zeros(glcm.shape[0] * 2)\n","  for i in range(0, glcm.shape[0]):\n","    for j in range(0, glcm.shape[1]):\n","      resultSum[i + j] += glcm[i,j]\n","      resultDiff[abs(i - j)] += glcm[i,j]\n","  return resultSum, resultDiff\n","\n","def glcmFeatures(glcm):\n","  fglcm = {}\n","\n","  #epsilon\n","  eps = 0.00000001\n","\n","  # sum probabilities\n","  probSum, probDiff = ProbSumDiff(glcm)\n","  \n","  sumEntropy = 0.0\n","  diffEntropy = 0.0\n","\n","  for i in range(0, len(probSum)):\n","    # sum of entropy\n","    sumEntropy += probSum[i] * np.log(probSum[i] + eps)\n","    # diff of entropy\n","    diffEntropy += probDiff[i] * np.log(probDiff[i] + eps)\n","\n","  fglcm['sumEntropy'] = -1 * sumEntropy\n","  fglcm['diffEntropy'] =  -1 * diffEntropy\n","  \n","  sumVariance = 0.0\n","  sumAverage = 0.0\n","  diffVariance = 0.0\n","\n","  for i in range(0, len(probSum)):\n","    # sum of variance\n","    sumVariance += (i - sumEntropy) * (i - sumEntropy) * probSum[i]\n","    # sum of average\n","    sumAverage += i * probSum[i]\n","    # diff of variance\n","    diffVariance += (i - diffEntropy) * (i - diffEntropy) * probDiff[i]\n","\n","  fglcm['sumVariance'] = sumVariance\n","  fglcm['sumAverage'] = sumAverage\n","  fglcm['diffVariance'] = diffVariance\n","  \n","  return fglcm"]},{"cell_type":"markdown","metadata":{"id":"KaPO61g5T6ae"},"source":["### Save features file"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BAEYOufxT7SH"},"outputs":[],"source":["def writeFeatures(features, flag, folder, image, name):\n","  if(flag):\n","    features.to_csv(os.path.join(folder,\n","                                 name + '.csv'),\n","                    mode='a',\n","                    index=False)\n","    flag = False\n","  else:\n","    features.to_csv(os.path.join(folder,\n","                                 name + '.csv'),\n","                  mode='a',\n","                  header=False,\n","                  index=False)\n","  return flag"]},{"cell_type":"markdown","metadata":{"id":"c9Y_4BwlUUX-"},"source":["### Main feature functions"]},{"cell_type":"markdown","metadata":{"id":"v-TCFlxpVK0q"},"source":["Haar + GLCM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"amBLMuF4UTJU"},"outputs":[],"source":["from pandas._libs.index import IndexEngine\n","from pandas.core.indexing import IndexingError\n","\n","def featuresExtractionHaarGLCM(matrix, candidates, features, image, folder):\n","  \n","  # no candidates, no extraction needed\n","  if (len(candidates) == 0):\n","    return []\n","\n","  # file\n","  flag = True\n","\n","  # for each candidate\n","  for index, candidate in enumerate(progress_bar(candidates)):\n","\n","    # to use them as coordinates they have to be integers\n","    candidate = candidate.astype(np.int64)\n","\n","    # candidates are y,x and sigma\n","    # tolerance to the window\n","    n = 7\n","\n","    # if it is not possible a square patch\n","    if (((candidate[1] - n) < 0) or \n","        ((candidate[1] + n) > matrix.shape[0]) or \n","        ((candidate[0] - n) < 0) or\n","        ((candidate[0] + n) > matrix.shape[1])):\n","      # ignore it\n","      continue\n","\n","    # defining limits \n","    left = int(candidate[1] - n)\n","    right = int(candidate[1] + n)\n","    top = int(candidate[0] - n)\n","    bottom = int(candidate[0] + n)\n","\n","    # getting patch / roi\n","    patchCandidate = matrix[top : bottom,\n","                            left : right]\n","\n","    # getting haar n= 2\n","    n = 2\n","    w = 'haar'\n","    coeffs = pywt.wavedec2(patchCandidate,wavelet=w,level=n)\n","    LL2, (LH2, HL2, HH2), (LH1, HL1, HH1) = coeffs\n","    \n","    # # decompose haar patches to use for feature extraction\n","    dictHaar = {'LL2':LL2, 'LH2':LH2, 'HL2': HL2, 'HH2': HH2, 'LH1':LH1, 'HL1': HL1, 'HH1': HH1}\n","\n","    # # for each haar decomposition\n","    for key, haar in dictHaar.items():\n","\n","      # starting the row values\n","      dictFeatures = {}\n","      dictFeatures = {'name': 'patch_' + str(index) + '_' + str(key) + '_' + str(image.split(\".\")[0]),\n","                      #'label': patchGroundTruth(top, bottom, left, right, groundTruth),\n","                      'x': candidate[0],\n","                      'y': candidate[1]}\n","\n","      # compute first order statistic features\n","      dictFos = functionFeatures(haar.astype(np.uint8))\n","      # saving it in the row values\n","      dictFeatures.update(dictFos)\n","\n","      # Relative smoothness\n","      dictFeatures['relativeSmoothness'] = 1 - ( 1 / (1.0 + dictFeatures[\"Variance\"]))\n","      \n","\n","      # input image, distance in pixels, angles\n","      glcm = feature.greycomatrix(haar.astype(np.uint8), [ 1 ], [ 0 ])\n","      \n","      # glcm features    \n","      # properties\n","      dictFeatures['contrast'] = feature.greycoprops(glcm, 'contrast')[0][0]\n","      dictFeatures['dissimilarity'] = feature.greycoprops(glcm, 'dissimilarity')[0][0]\n","      dictFeatures['homogeneity'] = feature.greycoprops(glcm, 'homogeneity')[0][0]\n","      dictFeatures['energy'] = feature.greycoprops(glcm, 'energy')[0][0]\n","      dictFeatures['correlation'] = feature.greycoprops(glcm, 'correlation')[0][0]\n","      dictFeatures['ASM'] = feature.greycoprops(glcm, 'ASM')[0][0]\n","\n","      dictFeatures['entropy'] = measure.shannon_entropy(glcm)\n","\n","      fglcm = glcmFeatures(glcm[:,:,0,0])\n","      dictFeatures.update(fglcm)\n","\n","      del glcm\n","\n","      # add to the dataframe the features for this patch\n","      features = features.append(dictFeatures, ignore_index=True)\n","\n","  # save in the csv\n","  writeFeatures(features, flag, folder, image, '_haar_glcm')\n","\n","  return features"]},{"cell_type":"markdown","metadata":{"id":"PaSWxkTbVStU"},"source":["LBP+GLCM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sPbPRJZZVUfb"},"outputs":[],"source":["def featuresExtractionLBPGLCM(matrix, candidates, features, image, folder):\n","  \n","  # no candidates, no extraction needed\n","  if (len(candidates) == 0):\n","    return []\n","\n","  # file\n","  flag = True\n","\n","  # for each candidate\n","  for index, candidate in enumerate(progress_bar(candidates)):\n","\n","    # to use them as coordinates they have to be integers\n","    candidate = candidate.astype(np.int64)\n","\n","    # tolerance to the window\n","    n = 7\n","\n","    # if it is not possible a square patch\n","    if (((candidate[1] - n) < 0) or \n","        ((candidate[1] + n) > matrix.shape[0]) or \n","        ((candidate[0] - n) < 0) or\n","        ((candidate[0] + n) > matrix.shape[1])):\n","      # ignore it\n","      continue\n","\n","    # defining limits \n","    left = int(candidate[1] - n)\n","    right = int(candidate[1] + n)\n","    top = int(candidate[0] - n)\n","    bottom = int(candidate[0] + n)\n","\n","    # getting patch / roi\n","    patchCandidate = matrix[top : bottom,\n","                            left : right]\n","\n","    # LBP received grayscale\n","\n","    radius= 1\n","    points= 8 * radius\n","\n","    patchCandidate = local_binary_pattern(patchCandidate, points, radius, method='default')\n","\n","    # starting the row values\n","    dictFeatures = {}\n","    dictFeatures = {'name': 'patch_' + str(index) + '_' + str(image.split(\".\")[0]),\n","                    #'label': patchGroundTruth(top, bottom, left, right, groundTruth),\n","                    'x': candidate[0],\n","                    'y': candidate[1]}\n","\n","    # compute first order statistic features\n","    dictFos = functionFeatures(patchCandidate.astype(np.uint8))\n","    \n","    # saving it in the row values\n","    dictFeatures.update(dictFos)\n","\n","    # Relative smoothness\n","    dictFeatures['relativeSmoothness'] = 1 - ( 1 / (1.0 + dictFeatures[\"Variance\"]))\n","    \n","\n","    # input image, distance in pixels, angles\n","    glcm = feature.greycomatrix(patchCandidate.astype(np.uint8), [ 1 ], [ 0 ])\n","    \n","    # glcm features    \n","    # properties\n","    dictFeatures['contrast'] = feature.greycoprops(glcm, 'contrast')[0][0]\n","    dictFeatures['dissimilarity'] = feature.greycoprops(glcm, 'dissimilarity')[0][0]\n","    dictFeatures['homogeneity'] = feature.greycoprops(glcm, 'homogeneity')[0][0]\n","    dictFeatures['energy'] = feature.greycoprops(glcm, 'energy')[0][0]\n","    dictFeatures['correlation'] = feature.greycoprops(glcm, 'correlation')[0][0]\n","    dictFeatures['ASM'] = feature.greycoprops(glcm, 'ASM')[0][0]\n","\n","    dictFeatures['entropy'] = measure.shannon_entropy(glcm)\n","    \n","    fglcm = glcmFeatures(glcm[:,:,0,0])\n","    dictFeatures.update(fglcm)\n","\n","    del glcm\n","\n","    # add to the dataframe the features for this patch\n","    features = features.append(dictFeatures, ignore_index=True)\n","\n","  # save in the csv\n","  writeFeatures(features, flag, folder, image, '_lbp_glcm')\n","\n","  return features"]},{"cell_type":"markdown","metadata":{"id":"IBe-Qe3MWRcy"},"source":["GLCM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C517LLypWRzS"},"outputs":[],"source":["from skimage import feature\n","\n","def featuresExtractionGLCM(matrix, candidates, features, image, folder):\n","  \n","  # no candidates, no extraction needed\n","  if (len(candidates) == 0):\n","    return []\n","\n","  # file\n","  flag = True\n","\n","  # for each candidate\n","  for index, candidate in enumerate(progress_bar(candidates)):\n","\n","    # to use them as coordinates they have to be integers\n","    candidate = candidate.astype(np.int64)\n","\n","    # tolerance to the window\n","    n = 7\n","\n","    # if it is not possible a square patch\n","    if (((candidate[1] - n) < 0) or \n","        ((candidate[1] + n) > matrix.shape[0]) or \n","        ((candidate[0] - n) < 0) or\n","        ((candidate[0] + n) > matrix.shape[1])):\n","      # ignore it\n","      continue\n","\n","    # defining limits \n","    left = int(candidate[1] - n)\n","    right = int(candidate[1] + n)\n","    top = int(candidate[0] - n)\n","    bottom = int(candidate[0] + n)\n","\n","    # getting patch / roi\n","    patchCandidate = matrix[top : bottom,\n","                            left : right]\n","\n","    # starting the row values\n","    dictFeatures = {}\n","    dictFeatures = {'name': 'patch_' + str(index) + '_' + str(image.split(\".\")[0]),\n","                    #'label': patchGroundTruth(top, bottom, left, right, groundTruth),\n","                    'x': candidate[0],\n","                    'y': candidate[1]}\n","\n","    # compute first order statistic features\n","\n","    dictFos = functionFeatures(patchCandidate.astype(np.uint8))\n","    # saving it in the row values\n","    dictFeatures.update(dictFos)\n","\n","      # Relative smoothness\n","    dictFeatures['relativeSmoothness'] = 1 - ( 1 / (1.0 + dictFeatures[\"Variance\"]))\n","    \n","    # input image, distance in pixels, angles\n","    glcm = feature.greycomatrix(patchCandidate.astype(np.uint8), [ 1 ], [ 0 ])\n","    \n","    # glcm features    \n","    # properties\n","    dictFeatures['contrast'] = feature.greycoprops(glcm, 'contrast')[0][0]\n","    dictFeatures['dissimilarity'] = feature.greycoprops(glcm, 'dissimilarity')[0][0]\n","    dictFeatures['homogeneity'] = feature.greycoprops(glcm, 'homogeneity')[0][0]\n","    dictFeatures['energy'] = feature.greycoprops(glcm, 'energy')[0][0]\n","    dictFeatures['correlation'] = feature.greycoprops(glcm, 'correlation')[0][0]\n","    dictFeatures['ASM'] = feature.greycoprops(glcm, 'ASM')[0][0]\n","\n","    dictFeatures['entropy'] = measure.shannon_entropy(glcm)\n","    fglcm = glcmFeatures(glcm[:,:,0,0])\n","    dictFeatures.update(fglcm)\n","\n","    del glcm\n","\n","    # add to the dataframe the features for this patch\n","    features = features.append(dictFeatures, ignore_index=True)\n","\n","  # save in the csv\n","  print(folder)\n","  print(image)\n","  writeFeatures(features, flag, folder, image, '_fos_glcm')\n","\n","  return features"]},{"cell_type":"markdown","metadata":{"id":"HghiWfL0KKuE"},"source":["## Additional Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F7FnrH_DIlEA"},"outputs":[],"source":["def imgDilation(matrix):\n","  kernel = np.ones((3,3), np.uint8)\n","  img_dilation = cv2.dilate(matrix, kernel, iterations=3)\n","  return img_dilation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0mAA5PVxyqpx"},"outputs":[],"source":["def runPipeline(imagePath, name, featuresOption, outputPath):\n","\n","  # to save the features generated with the glcm\n","  features = pd.DataFrame(dtype=np.float64)\n","\n","  imageName = imagePath.split('/')[-1]\n","  print(imageName)\n","  #upload images\n","  img = cv2.imread(imagePath, cv2.IMREAD_UNCHANGED)\n","  imgCopy = copy.deepcopy(img)\n","\n","  # pipelines\n","  if name == 'pipelineA':\n","    # preprocessing\n","\n","    # dehazing\n","    preprocessed = cv2.cvtColor(imgCopy, cv2.COLOR_GRAY2BGR)\n","\n","    preprocessed = deHazingDarkChannelPrior(preprocessed)\n","\n","    cv2.imwrite(os.path.join(outputPath, imageName.split('.')[0]+'_dehazing.png'), preprocessed)\n","\n","    # dilation\n","    preprocessedDil = imgDilation(preprocessed)\n","\n","    cv2.imwrite(os.path.join(outputPath, imageName.split('.')[0]+'_dehazing_dilation.png'), preprocessedDil)\n","\n","    # candidate extraction\n","\n","    preprocessedDil = preprocessedDil.astype(np.float32)\n","    preprocessedDil = cv2.cvtColor(preprocessedDil, cv2.COLOR_BGR2GRAY)\n","\n","    candidates = candidateExtractionDoG(preprocessedDil.astype(np.uint8), minSigma=0.0001, maxSigma=30, threshold=0.04)\n","\n","  elif name == 'pipelineB':\n","    # preprocessing\n","    \n","    # clahe\n","    preprocessed = imgCLAHE(imgCopy)\n","    preprocessed = cv2.cvtColor(preprocessed, cv2.COLOR_GRAY2BGR)\n","    cv2.imwrite(os.path.join(outputPath, imageName.split('.')[0]+'_clahe.png'), preprocessed)\n","\n","    # dehazing \n","    preprocessed = deHazingDarkChannelPrior(preprocessed)\n","    cv2.imwrite(os.path.join(outputPath, imageName.split('.')[0]+'_clahe_dehazing.png'), preprocessed)\n","\n","    # dilation\n","    preprocessedDil = imgDilation(preprocessed)\n","    cv2.imwrite(os.path.join(outputPath, imageName.split('.')[0]+'_clahe_dehazing_dilation.png'), preprocessedDil)\n","    # candidate extraction\n","\n","    preprocessedDil = preprocessedDil.astype(np.float32)\n","    preprocessedDil = cv2.cvtColor(preprocessedDil, cv2.COLOR_BGR2GRAY)\n","\n","    candidates = candidateExtractionDoG(preprocessedDil.astype(np.uint8), minSigma=0.005, maxSigma=50, threshold=0.04)\n","\n","\n","  elif name == 'pipelineD':\n","    # preprocessing\n","\n","    # clahe\n","    preprocessed = imgCLAHE(imgCopy)\n","    preprocessed = cv2.cvtColor(preprocessed, cv2.COLOR_GRAY2BGR)\n","    cv2.imwrite(os.path.join(outputPath, imageName.split('.')[0]+'_clahe.png'), preprocessed)\n","\n","    # dehazing \n","    preprocessed = deHazingDarkChannelPrior(preprocessed)\n","    cv2.imwrite(os.path.join(outputPath, imageName.split('.')[0]+'_clahe_dehazing.png'), preprocessed)\n","\n","    # dilation\n","\n","    preprocessedDil = imgDilation(preprocessed)\n","    cv2.imwrite(os.path.join(outputPath, imageName.split('.')[0]+'_clahe_dehazing_dilation.png'), preprocessedDil)\n","    # candidate extraction\n","\n","    preprocessedDil = preprocessedDil.astype(np.float32)\n","    preprocessedDil = cv2.cvtColor(preprocessedDil, cv2.COLOR_BGR2GRAY)\n","\n","    candidates = candidateExtractionDoG(preprocessedDil.astype(np.uint8), minSigma=0.005, maxSigma=50, threshold=0.04)\n","\n","  else:\n","    print('invalid pipeline')\n","\n","  print('candidates detected, ', len(candidates))\n","\n","  # feature extraction \n","\n","  copyPreprocessed = copy.deepcopy(preprocessed)\n","    \n","  copyPreprocessed = copyPreprocessed.astype(np.uint16)\n","  copyPreprocessed = cv2.cvtColor(copyPreprocessed, cv2.COLOR_BGR2GRAY)\n","\n","\n","  if featuresOption == 'GLCM':\n","    featuresExtractionGLCM(copyPreprocessed, candidates, features, imagePath, outputPath)\n","  elif featuresOption == 'HaarGLCM':\n","    featuresExtractionHaarGLCM(copyPreprocessed, candidates, features, imagePath, outputPath)\n","  elif featuresOption == 'LBPGLCM':\n","    featuresExtractionLBPGLCM(copyPreprocessed, candidates, features, imagePath, outputPath)\n"]},{"cell_type":"markdown","metadata":{"id":"D9x8KyyfIlcc"},"source":["# Main"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":126},"id":"HxvFBG8zYwQZ","executionInfo":{"status":"ok","timestamp":1657122410790,"user_tz":-120,"elapsed":238552,"user":{"displayName":"EMILY ESMERALDA CARVAJAL CAMELO","userId":"02914831594555779435"}},"outputId":"6948366e-5c76-42b6-d3ad-fd56981ec815"},"outputs":[{"output_type":"stream","name":"stdout","text":["22580098_6200187f3f1ccc18_MG_L_ML_ANON.tif\n","candidates detected,  1635\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","<style>\n","    /* Turns off some styling */\n","    progress {\n","        /* gets rid of default border in Firefox and Opera. */\n","        border: none;\n","        /* Needs to be in here for Safari polyfill so background images work as expected. */\n","        background-size: auto;\n","    }\n","    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","        background: #F44336;\n","    }\n","</style>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      <progress value='1635' class='' max='1635' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      100.00% [1635/1635 03:02<00:00]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/test\n","/content/drive/MyDrive/Image Processing and Analysis 2022/projects/Calcification Detection/dataset/images/22580098_6200187f3f1ccc18_MG_L_ML_ANON.tif\n"]}],"source":["DATA_DIR = os.path.join('/content',\n","                        'drive',\n","                        'MyDrive',\n","                        'Image Processing and Analysis 2022',\n","                        'projects',\n","                        'Calcification Detection',\n","                        'dataset')\n","\n","runPipeline(os.path.join(DATA_DIR, 'images', '22580098_6200187f3f1ccc18_MG_L_ML_ANON.tif'),\n","            'pipelineD',\n","            'GLCM',\n","            os.path.join('/content',\n","                         'drive',\n","                         'MyDrive',\n","                         'test'))"]}],"metadata":{"colab":{"collapsed_sections":["p2yUjSTALLF8","1Rpfjyp7IcDp","KaPO61g5T6ae"],"machine_shape":"hm","name":"ImageProcessingMCD.ipynb","provenance":[{"file_id":"1ty3imxgrzxRoN3M7N4EIw5lEy7pM1n8Y","timestamp":1657122607805}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}